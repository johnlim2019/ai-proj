{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"./data/WELFake_Dataset.csv\")\n",
    "print(df.columns)\n",
    "print(df.shape)\n",
    "\n",
    "text_iterator = df['text']\n",
    "title_iterator = df['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72134\n",
      "72134\n",
      "['now', 'most', 'of', 'the', 'demonstrators', 'gathered', 'last', 'night', 'were', 'exercising', 'their', 'constitutional', 'and', 'protected', 'right', 'to', 'peaceful', 'protest', 'in', 'order', 'to', 'raise', 'issues', 'and', 'create', 'change', 'loretta', 'lynch', 'aka', 'eric', 'holder', 'in', 'a', 'skirt']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def process_text(text_iterator):\n",
    "    text_processed = []\n",
    "    for text in text_iterator:\n",
    "        try:\n",
    "            # remove punctuation\n",
    "            t = re.sub(\"[^a-zA-Z0-9]\", \" \", text)\n",
    "            # remove multiple spaces\n",
    "            t = re.sub(r\" +\", \" \", t)\n",
    "            # remove newline\n",
    "            t = re.sub(r\"\\n\", \" \", t)\n",
    "            # clear trailing whitespaces\n",
    "            t = t.strip()\n",
    "            # lowercase\n",
    "            t = t.lower()\n",
    "            # tokenise\n",
    "            t = t.split(\" \")\n",
    "            text_processed.append(t)\n",
    "        except:\n",
    "            text_processed.append(None)\n",
    "            continue\n",
    "    return text_processed\n",
    "\n",
    "text_processed = process_text(text_iterator)\n",
    "title_processed = process_text(title_iterator)\n",
    "\n",
    "print(len(text_processed))\n",
    "print(len(title_processed))\n",
    "print(text_processed[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/limjohn/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['demonstrators', 'gathered', 'last', 'night', 'exercising', 'constitutional', 'protected', 'right', 'peaceful', 'protest', 'order', 'raise', 'issues', 'create', 'change', 'loretta', 'lynch', 'aka', 'eric', 'holder', 'skirt']\n",
      "72134\n",
      "72134\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "\n",
    "def remove_stop_words_inner(text, stop_words):\n",
    "    no_stop_words = []\n",
    "    if text is None:\n",
    "        return None\n",
    "    for token in text:\n",
    "        if token not in stop_words:\n",
    "            no_stop_words.append(token)\n",
    "    return no_stop_words\n",
    "\n",
    "\n",
    "def remove_stop_words_outer(text_list, stop_words):\n",
    "    for index, text in enumerate(text_list):\n",
    "        t = remove_stop_words_inner(text, stop_words)\n",
    "        text_list[index] = t\n",
    "    return text_list\n",
    "\n",
    "\n",
    "text_no_stop_words = remove_stop_words_outer(text_processed, stop_words)\n",
    "title_no_stop_words = remove_stop_words_outer(title_processed, stop_words)\n",
    "print(text_no_stop_words[2])\n",
    "print(len(text_no_stop_words))\n",
    "print(len(title_no_stop_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index                                              title  \\\n",
      "0      0  [law, enforcement, high, alert, following, thr...   \n",
      "1      1                                               None   \n",
      "2      2  [unbelievable, obama, attorney, general, says,...   \n",
      "3      3  [bobby, jindal, raised, hindu, uses, story, ch...   \n",
      "4      4  [satan, 2, russia, unvelis, image, terrifying,...   \n",
      "\n",
      "                                                text  class  \n",
      "0  [comment, expected, barack, obama, members, fy...      1  \n",
      "1                    [post, votes, hillary, already]      1  \n",
      "2  [demonstrators, gathered, last, night, exercis...      1  \n",
      "3  [dozen, politically, active, pastors, came, pr...      0  \n",
      "4  [rs, 28, sarmat, missile, dubbed, satan, 2, re...      1  \n"
     ]
    }
   ],
   "source": [
    "df_output = pd.DataFrame(columns=[\"index\", \"title\", \"text\", \"class\"])\n",
    "df_output[\"title\"] = title_no_stop_words\n",
    "df_output[\"text\"] = text_no_stop_words\n",
    "df_output[\"index\"] = np.arange(len(title_no_stop_words))\n",
    "df_output[\"class\"] = df[\"label\"]\n",
    "print(df_output.head())\n",
    "df_output.to_csv(\"./data/clean_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
