{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'title', 'text', 'label'], dtype='object')\n",
      "(72134, 4)\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"./data/WELFake_Dataset.csv\")\n",
    "print(df.columns)\n",
    "print(df.shape)\n",
    "print(type(df.loc[7,\"text\"]))\n",
    "\n",
    "text_iterator = df['text']\n",
    "title_iterator = df['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72134\n",
      "72134\n",
      "['now', 'most', 'of', 'the', 'demonstrators', 'gathered', 'last', 'night', 'were', 'exercising', 'their', 'constitutional', 'and', 'protected', 'right', 'to', 'peaceful', 'protest', 'in', 'order', 'to', 'raise', 'issues', 'and', 'create', 'change', 'loretta', 'lynch', 'aka', 'eric', 'holder', 'in', 'a', 'skirt']\n"
     ]
    }
   ],
   "source": [
    "def process_text(text_iterator):\n",
    "    text_processed = []\n",
    "    for text in text_iterator:        \n",
    "        try:\n",
    "            # remove punctuation\n",
    "            t = re.sub(\"[^a-zA-Z0-9]\", \" \", text)\n",
    "            # remove multiple spaces\n",
    "            t = re.sub(r\" +\", \" \", t)\n",
    "            # remove newline\n",
    "            t = re.sub(r\"\\n\", \" \", t)\n",
    "            # clear trailing whitespaces\n",
    "            t = t.strip()\n",
    "            # lowercase\n",
    "            t = t.lower()\n",
    "            # tokenise\n",
    "            t = t.split(\" \")\n",
    "            # drop empty string\n",
    "            t = list(filter(lambda x: x != \"\", t))\n",
    "            if len(t) == 0:\n",
    "                text_processed.append(None)\n",
    "            else:\n",
    "                text_processed.append(t)\n",
    "        except:\n",
    "            text_processed.append(None)\n",
    "            continue\n",
    "    return text_processed\n",
    "\n",
    "\n",
    "text_processed = process_text(text_iterator)\n",
    "title_processed = process_text(title_iterator)\n",
    "\n",
    "print(len(text_processed))\n",
    "print(len(title_processed))\n",
    "print(text_processed[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/limjohn/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['demonstrators', 'gathered', 'last', 'night', 'exercising', 'constitutional', 'protected', 'right', 'peaceful', 'protest', 'order', 'raise', 'issues', 'create', 'change', 'loretta', 'lynch', 'aka', 'eric', 'holder', 'skirt']\n",
      "72134\n",
      "72134\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "\n",
    "def remove_stop_words_inner(text, stop_words):\n",
    "    no_stop_words = []\n",
    "    if text is None:\n",
    "        return None\n",
    "    for token in text:\n",
    "        if token not in stop_words:\n",
    "            no_stop_words.append(token)\n",
    "    return no_stop_words\n",
    "\n",
    "\n",
    "def remove_stop_words_outer(text_list, stop_words):\n",
    "    for index, text in enumerate(text_list):\n",
    "        t = remove_stop_words_inner(text, stop_words)\n",
    "        text_list[index] = t\n",
    "    return text_list\n",
    "\n",
    "\n",
    "text_no_stop_words = remove_stop_words_outer(text_processed, stop_words)\n",
    "title_no_stop_words = remove_stop_words_outer(title_processed, stop_words)\n",
    "print(text_no_stop_words[2])\n",
    "print(len(text_no_stop_words))\n",
    "print(len(title_no_stop_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output = pd.DataFrame(columns=[\"index\", \"title\", \"text\", \"class\"])\n",
    "df_output[\"title\"] = title_no_stop_words\n",
    "df_output[\"text\"] = text_no_stop_words\n",
    "df_output[\"index\"] = np.arange(len(title_no_stop_words))\n",
    "df_output[\"class\"] = df[\"label\"]\n",
    "df_output.to_csv(\"./data/clean_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As title and text contribute differently to the prediction. so we should create two types of table, we will inherit the index so we can match the title and texts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = df_output.drop(columns=\"title\")\n",
    "df_text = df_text[df_text[\"text\"].notnull()]\n",
    "df_title = df_output.drop(columns=\"text\")\n",
    "df_title = df_title[df_title[\"title\"].notnull()]\n",
    "\n",
    "df_text.to_pickle('./data/clean_text.pkl')\n",
    "df_text.to_csv('./data/clean_text.csv')\n",
    "df_title.to_pickle('./data/clean_title.pkl')\n",
    "df_title.to_csv('./data/clean_title.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
