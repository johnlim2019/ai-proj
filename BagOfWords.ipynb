{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJnPRMzviivZ",
        "outputId": "25443b2f-68a4-4ecc-dbec-6d9ed21fa517"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import re\n",
        "import nltk\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import wordnet as wn\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "060OV4aVXGWt",
        "outputId": "91b8f8f6-ee25-48e6-d695-2ac8323d6639"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWNQiKlWkgS9",
        "outputId": "c0ed9821-c231-4b03-852f-fc33ea23998e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Unnamed: 0', 'title', 'text', 'label'], dtype='object')\n",
            "(72134, 4)\n",
            "<class 'str'>\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/data/WELFake_Dataset.csv\")\n",
        "print(df.columns)\n",
        "print(df.shape)\n",
        "print(type(df.loc[7,\"text\"]))\n",
        "\n",
        "text_iterator = df['text']\n",
        "title_iterator = df['title']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Zzj2mt6y2whk",
        "outputId": "3408a3db-34d8-4e34-df9e-e64c7c6cddd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "72134\n",
            "72134\n",
            "demonstr gather last night exercis constitut protect right peac protest order rais issu creat chang loretta lynch aka eric holder skirt\n"
          ]
        }
      ],
      "source": [
        "# with stemming and removing stop words with nltk\n",
        "ps = PorterStemmer()\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "def process_text(text_iterator):\n",
        "    text_processed = []\n",
        "    for text in text_iterator:\n",
        "        try:\n",
        "            # remove punctuation\n",
        "            t = re.sub(\"[^a-zA-Z0-9]\", \" \", text)\n",
        "            # remove multiple spaces\n",
        "            t = re.sub(r\" +\", \" \", t)\n",
        "            # remove newline\n",
        "            t = re.sub(r\"\\n\", \" \", t)\n",
        "            # clear trailing whitespaces\n",
        "            t = t.strip()\n",
        "            # lowercase\n",
        "            t = t.lower()\n",
        "            # tokenise\n",
        "            t = t.split(\" \")\n",
        "            # drop empty string\n",
        "            t = list(filter(lambda x: x != \"\", t))\n",
        "            # stem the words\n",
        "            new_t = []\n",
        "            for w in t:\n",
        "              new_word = ps.stem(w)\n",
        "              if new_word not in (stop_words):\n",
        "                new_t.append(new_word)\n",
        "            # rejoin tokenized string\n",
        "            t = \" \".join(new_t)\n",
        "            if len(t) == 0:\n",
        "                text_processed.append(\"\")\n",
        "            else:\n",
        "                text_processed.append(t)\n",
        "        except:\n",
        "            text_processed.append(\"\")\n",
        "            continue\n",
        "    return text_processed\n",
        "\n",
        "\n",
        "text_processed = process_text(text_iterator)\n",
        "title_processed = process_text(title_iterator)\n",
        "\n",
        "print(len(text_processed))\n",
        "print(len(title_processed))\n",
        "print(text_processed[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIEzKFzzEKL4"
      },
      "outputs": [],
      "source": [
        "# just stemming of words\n",
        "def process_text2(text_iterator):\n",
        "    text_processed = []\n",
        "    for text in text_iterator:\n",
        "        try:\n",
        "            # remove punctuation\n",
        "            t = re.sub(\"[^a-zA-Z0-9_.,!\\\"\\'/$]\", \" \", text)\n",
        "            # remove multiple spaces\n",
        "            t = re.sub(r\" +\", \" \", t)\n",
        "            # remove newline\n",
        "            t = re.sub(r\"\\n\", \" \", t)\n",
        "            # clear trailing whitespaces\n",
        "            t = t.strip()\n",
        "            # tokenise\n",
        "            t = t.split(\" \")\n",
        "            # drop empty string\n",
        "            t = list(filter(lambda x: x != \"\", t))\n",
        "            # stem the words\n",
        "            new_t = []\n",
        "            for w in t:\n",
        "              new_word = ps.stem(w)\n",
        "              new_t.append(new_word)\n",
        "            # rejoin tokenized string\n",
        "            t = \" \".join(new_t)\n",
        "            if len(t) == 0:\n",
        "                text_processed.append(\"\")\n",
        "            else:\n",
        "                text_processed.append(t)\n",
        "        except:\n",
        "            text_processed.append(\"\")\n",
        "            continue\n",
        "    return text_processed\n",
        "\n",
        "\n",
        "text_processed = process_text2(text_iterator)\n",
        "title_processed = process_text2(title_iterator)\n",
        "\n",
        "print(len(text_processed))\n",
        "print(len(title_processed))\n",
        "print(text_processed[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqIIVaa-cqst",
        "outputId": "8a0d2a2f-7d85-4e91-8bf9-02a343e8a075"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "72134\n",
            "72134\n",
            "Now, most of the demonstrators gathered last night were exercising their constitutional and protected right to peaceful protest in order to raise issues and create change. Loretta Lynch aka Eric Holder in a skirt\n"
          ]
        }
      ],
      "source": [
        "# no stemming and removing stop words\n",
        "def process_text3(text_iterator):\n",
        "    text_processed = []\n",
        "    for text in text_iterator:\n",
        "        try:\n",
        "            # remove punctuation\n",
        "            t = re.sub(\"[^a-zA-Z0-9_.,!\\\"\\'/$]\", \" \", text)\n",
        "            # remove multiple spaces\n",
        "            t = re.sub(r\" +\", \" \", t)\n",
        "            # remove newline\n",
        "            t = re.sub(r\"\\n\", \" \", t)\n",
        "            # clear trailing whitespaces\n",
        "            t = t.strip()\n",
        "            # tokenise\n",
        "            t = t.split(\" \")\n",
        "            # drop empty string\n",
        "            t = list(filter(lambda x: x != \"\", t))\n",
        "            # join back the string\n",
        "            new_t = []\n",
        "            for w in t:\n",
        "              new_t.append(w)\n",
        "            # rejoin tokenized string\n",
        "            t = \" \".join(new_t)\n",
        "            if len(t) == 0:\n",
        "                text_processed.append(\"\")\n",
        "            else:\n",
        "                text_processed.append(t)\n",
        "        except:\n",
        "            text_processed.append(\"\")\n",
        "            continue\n",
        "    return text_processed\n",
        "\n",
        "\n",
        "text_processed = process_text3(text_iterator)\n",
        "title_processed = process_text3(title_iterator)\n",
        "\n",
        "print(len(text_processed))\n",
        "print(len(title_processed))\n",
        "print(text_processed[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pRFkYY5U_n2",
        "outputId": "5e0ac7ea-f152-41f7-b9bd-60c8c63afdc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UNBELIEVABLE! OBAMA S ATTORNEY GENERAL SAYS MOST CHARLOTTE RIOTERS WERE PEACEFUL PROTESTERS In Her Home State Of North Carolina VIDEO Now, most of the demonstrators gathered last night were exercising their constitutional and protected right to peaceful protest in order to raise issues and create change. Loretta Lynch aka Eric Holder in a skirt\n"
          ]
        }
      ],
      "source": [
        "merged_title_text = []\n",
        "for i,v in enumerate(title_processed):\n",
        "    if (v == None):\n",
        "        merge = text_processed[i]\n",
        "    elif (text_processed[i]==None):\n",
        "        merge = v\n",
        "    else:\n",
        "        merge = v + \" \" + text_processed[i]\n",
        "    merged_title_text.append(merge)\n",
        "\n",
        "print(merged_title_text[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10ejZniS3NNa"
      },
      "outputs": [],
      "source": [
        "df_output = pd.DataFrame(columns=[\"title\", \"text\", \"merged\", \"class\"])\n",
        "df_output[\"title\"] = title_processed\n",
        "df_output[\"text\"] = text_processed\n",
        "df_output[\"merged\"] = merged_title_text\n",
        "df_output[\"class\"] = df[\"label\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xE3ryPL_3qe6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56c2353f-52b1-4aeb-c849-fde52451c218"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['LAW ENFORCEMENT ON HIGH ALERT Following Threats Against Cops And Whites On 9 11By BlackLivesMatter And FYF911 Terrorists VIDEO No comment is expected from Barack Obama Members of the FYF911 or FukYoFlag and BlackLivesMatter movements called for the lynching and hanging of white people and cops. They encouraged others on a radio show Tuesday night to turn the tide and kill white people and cops to send a message about the killing of black people in America.One of the F YoFlag organizers is called Sunshine. She has a radio blog show hosted from Texas called, Sunshine s F ing Opinion Radio Show. A snapshot of her FYF911 LOLatWhiteFear Twitter page at 9 53 p.m. shows that she was urging supporters to Call now!! fyf911 tonight we continue to dismantle the illusion of white Below is a SNAPSHOT Twitter Radio Call Invite FYF911The radio show aired at 10 00 p.m. eastern standard time.During the show, callers clearly call for lynching and killing of white people.A 2 39 minute clip from the radio show can be heard here. It was provided to Breitbart Texas by someone who would like to be referred to as Hannibal. He has already received death threats as a result of interrupting FYF911 conference calls.An unidentified black man said when those mother f kers are by themselves, that s when when we should start f ing them up. Like they do us, when a bunch of them ni ers takin one of us out, that s how we should roll up. He said, Cause we already roll up in gangs anyway. There should be six or seven black mother f ckers, see that white person, and then lynch their ass. Let s turn the tables. They conspired that if cops started losing people, then there will be a state of emergency. He speculated that one of two things would happen, a big ass R s war, or ni ers, they are going to start backin up. We are already getting killed out here so what the f k we got to lose Sunshine could be heard saying, Yep, that s true. That s so f king true. He said, We need to turn the tables on them. Our kids are getting shot out here. Somebody needs to become a sacrifice on their side.He said, Everybody ain t down for that s t, or whatever, but like I say, everybody has a different position of war. He continued, Because they don t give a f k anyway. He said again, We might as well utilized them for that s t and turn the tables on these n ers. He said, that way we can start lookin like we ain t havin that many casualties, and there can be more causalities on their side instead of ours. They are out their killing black people, black lives don t matter, that s what those mother f kers so we got to make it matter to them. Find a mother f ker that is alone. Snap his ass, and then f in hang him from a damn tree. Take a picture of it and then send it to the mother f kers. We just need one example, and then people will start watchin . This will turn the tables on s t, he said. He said this will start a trickle down effect. He said that when one white person is hung and then they are just flat hanging, that will start the trickle down effect. He continued, Black people are good at starting trends. He said that was how to get the upper hand. Another black man spoke up saying they needed to kill cops that are killing us. The first black male said, That will be the best method right there. Breitbart Texas previously reported how Sunshine was upset when racist white people infiltrated and disrupted one of her conference calls. She subsequently released the phone number of one of the infiltrators. The veteran immediately started receiving threatening calls.One of the F YoFlag movement supporters allegedly told a veteran who infiltrated their publicly posted conference call, We are going to rape and gut your pregnant wife, and your f ing piece of sh t unborn creature will be hung from a tree. Breitbart Texas previously encountered Sunshine at a Sandra Bland protest at the Waller County Jail in Texas, where she said all white people should be killed. She told journalists and photographers, You see this nappy ass hair on my head That means I am one of those more militant Negroes. She said she was at the protest because these redneck mother f kers murdered Sandra Bland because she had nappy hair like me. FYF911 black radicals say they will be holding the imperial powers that are actually responsible for the terrorist attacks on September 11th accountable on that day, as reported by Breitbart Texas. There are several websites and Twitter handles for the movement. Palmetto Star describes himself as one of the head organizers. He said in a YouTube video that supporters will be burning their symbols of the illusion of their superiority, their false white supremacy, like the American flag, the British flag, police uniforms, and Ku Klux Klan hoods.Sierra McGrone or Nocturnus Libertus posted, you too can help a young Afrikan clean their a with the rag of oppression. She posted two photos, one that appears to be herself, and a photo of a black man, wiping their naked butts with the American flag.For entire story Breitbart News'\n",
            " ' Did they post their votes for Hillary already'\n",
            " 'UNBELIEVABLE! OBAMA S ATTORNEY GENERAL SAYS MOST CHARLOTTE RIOTERS WERE PEACEFUL PROTESTERS In Her Home State Of North Carolina VIDEO Now, most of the demonstrators gathered last night were exercising their constitutional and protected right to peaceful protest in order to raise issues and create change. Loretta Lynch aka Eric Holder in a skirt']\n",
            "[[0]\n",
            " [0]\n",
            " [1]]\n"
          ]
        }
      ],
      "source": [
        "# split test and training dataset\n",
        "# separator = 10000\n",
        "separator = round(0.8*len(df_output[\"merged\"]))\n",
        "\n",
        "x_train = np.array(df_output[\"merged\"][:separator])\n",
        "y_train = []\n",
        "ls = []\n",
        "for i in df_output[\"class\"][:separator]:\n",
        "  ls.append(i)\n",
        "  y_train.append(ls)\n",
        "  ls = []\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "x_test = np.array(df_output[\"merged\"][separator+1:])\n",
        "y_test = []\n",
        "ls = []\n",
        "for i in df_output[\"class\"][separator+1:]:\n",
        "  ls.append(i)\n",
        "  y_test.append(ls)\n",
        "  ls = []\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "print(x_train[0:3])\n",
        "print(y_test[0:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5cCKPs24bZy"
      },
      "outputs": [],
      "source": [
        "# get text length\n",
        "def get_text_length(x):\n",
        "    return np.array([len(t) for t in x]).reshape(-1, 1)\n",
        "\n",
        "# print((get_text_length(x_test[5:15])))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get pos of words\n",
        "def get_pos_words(x):\n",
        "  n_ctr, a_ctr, v_ctr, r_ctr, others = 0, 0, 0, 0, 0\n",
        "  classified = \"\"\n",
        "  counters = []\n",
        "  output = []\n",
        "  for t in x:\n",
        "    counters = []\n",
        "    n_ctr, a_ctr, v_ctr, r_ctr, others = 0, 0, 0, 0, 0\n",
        "    for w in t.split(\" \"):\n",
        "      if wn.synsets(w):\n",
        "        classified = wn.synsets(w)[0].pos()\n",
        "        if classified == \"n\": n_ctr+=1\n",
        "        elif classified == \"a\": a_ctr+=1\n",
        "        elif classified == \"v\": v_ctr+=1\n",
        "        elif classified == \"r\": r_ctr+=1\n",
        "      else: others+=1\n",
        "    counters.append(n_ctr/len(t.split(\" \")))\n",
        "    counters.append(a_ctr/len(t.split(\" \")))\n",
        "    counters.append(v_ctr/len(t.split(\" \")))\n",
        "    counters.append(r_ctr/len(t.split(\" \")))\n",
        "    counters.append(others/len(t.split(\" \")))\n",
        "    output.append(counters)\n",
        "  return np.array(output)\n",
        "  # return np.array([wn.synsets(w)[0].pos() for w in x]).reshape(-1, -1)\n",
        "# for w in words:\n",
        "#     tmp = wn.synsets(w)[0].pos()\n",
        "#     print w, \":\", tmp\n",
        "# print(get_pos_words(x_test[5:15]))"
      ],
      "metadata": {
        "id": "Es6hvXuJXk8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmH7uvMzmk6k"
      },
      "outputs": [],
      "source": [
        "# get no. of capital letters\n",
        "def get_capital_letters(x):\n",
        "  counter = 0\n",
        "  total = []\n",
        "  for t in x:\n",
        "    number = []\n",
        "    counter = 0\n",
        "    for l in t:\n",
        "      if l.isupper(): counter+=1\n",
        "    number.append(counter/len(t))\n",
        "    total.append(number)\n",
        "  return np.array(total)\n",
        "\n",
        "# print((get_capital_letters(x_test[5:10])))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "waiHEyknBxYu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "618da1ae-0316-4a46-8eb6-929831a9ea0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12481\n",
            "0.8651739914044088\n"
          ]
        }
      ],
      "source": [
        "# normal bag of words model\n",
        "classifier = Pipeline([\n",
        "    ('vectorizer', CountVectorizer(min_df=0,max_df=1.0)),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', MultinomialNB())])\n",
        "classifier.fit(x_train, y_train.ravel())\n",
        "\n",
        "predicted = classifier.predict(x_test)\n",
        "num_correct = 0\n",
        "for i in range(len(predicted)):\n",
        "  if predicted[i] == y_test[i]:\n",
        "    num_correct += 1\n",
        "\n",
        "print(num_correct)\n",
        "print(num_correct/len(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lN6OP4Az4frx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7414c19-ede0-4fe9-f9f6-619e9bbf66bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12350\n",
            "0.856093165118536\n"
          ]
        }
      ],
      "source": [
        "# bag of words model with text length\n",
        "classifier2 = Pipeline([\n",
        "    ('features', FeatureUnion([\n",
        "        ('text', Pipeline([\n",
        "            ('vectorizer', CountVectorizer(min_df=0,max_df=1.0)),\n",
        "            ('tfidf', TfidfTransformer()),\n",
        "        ])),\n",
        "        ('length', Pipeline([\n",
        "            ('count', FunctionTransformer(get_text_length, validate=False)),\n",
        "        ]))\n",
        "    ])),\n",
        "    ('clf', MultinomialNB())])\n",
        "\n",
        "classifier2.fit(x_train, y_train.ravel())\n",
        "predicted2 = classifier2.predict(x_test)\n",
        "# predicted\n",
        "\n",
        "num_correct = 0\n",
        "for i in range(len(predicted2)):\n",
        "  if predicted2[i] == y_test[i]:\n",
        "    num_correct += 1\n",
        "\n",
        "print(num_correct)\n",
        "print(num_correct/len(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsAcNrFYdj08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "166114fb-c3d4-40fe-e0bb-5e0df1297832"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12335\n",
            "0.8550533758491612\n"
          ]
        }
      ],
      "source": [
        "# normal bag of words model with length and pos\n",
        "classifier3 = Pipeline([\n",
        "    ('features', FeatureUnion([\n",
        "        ('text', Pipeline([\n",
        "            ('vectorizer', CountVectorizer(min_df=0,max_df=1.0)),\n",
        "            ('tfidf', TfidfTransformer()),\n",
        "        ])),\n",
        "        ('length', Pipeline([\n",
        "            ('count', FunctionTransformer(get_text_length, validate=False)),\n",
        "        ])),\n",
        "        ('pos', Pipeline([\n",
        "            ('count', FunctionTransformer(get_pos_words, validate=False)),\n",
        "        ]))\n",
        "    ])),\n",
        "    ('clf', MultinomialNB())])\n",
        "\n",
        "classifier3.fit(x_train, y_train.ravel())\n",
        "\n",
        "predicted3 = classifier3.predict(x_test)\n",
        "num_correct = 0\n",
        "for i in range(len(predicted3)):\n",
        "  if predicted3[i] == y_test[i]:\n",
        "    num_correct += 1\n",
        "\n",
        "print(num_correct)\n",
        "print(num_correct/len(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98426b69-55e7-44f8-86a9-aa2211be02cf",
        "id": "YMdjMcN-dpSi"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12337\n",
            "0.8551920144184112\n"
          ]
        }
      ],
      "source": [
        "# normal bag of words model with length and pos and proportion of capital letters\n",
        "classifier4 = Pipeline([\n",
        "    ('features', FeatureUnion([\n",
        "        ('text', Pipeline([\n",
        "            ('vectorizer', CountVectorizer(min_df=0,max_df=1.0)),\n",
        "            ('tfidf', TfidfTransformer()),\n",
        "        ])),\n",
        "        ('length', Pipeline([\n",
        "            ('count', FunctionTransformer(get_text_length, validate=False)),\n",
        "        ])),\n",
        "        ('pos', Pipeline([\n",
        "            ('count', FunctionTransformer(get_pos_words, validate=False)),\n",
        "        ])),\n",
        "        ('capital', Pipeline([\n",
        "            ('count', FunctionTransformer(get_capital_letters, validate=False)),\n",
        "        ]))\n",
        "    ])),\n",
        "    ('clf', MultinomialNB())])\n",
        "\n",
        "classifier4.fit(x_train, y_train.ravel())\n",
        "\n",
        "predicted4 = classifier4.predict(x_test)\n",
        "num_correct = 0\n",
        "for i in range(len(predicted4)):\n",
        "  if predicted4[i] == y_test[i]:\n",
        "    num_correct += 1\n",
        "\n",
        "print(num_correct)\n",
        "print(num_correct/len(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac696fe7-df31-4306-d35c-f5d915e9ed68",
        "id": "fuYeCRVvItbZ"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12506\n",
            "0.8669069735200333\n"
          ]
        }
      ],
      "source": [
        "# normal bag of words model and proportion of capital letters\n",
        "classifier5 = Pipeline([\n",
        "    ('features', FeatureUnion([\n",
        "        ('text', Pipeline([\n",
        "            ('vectorizer', CountVectorizer(min_df=0,max_df=1.0)),\n",
        "            ('tfidf', TfidfTransformer()),\n",
        "        ])),\n",
        "        ('capital', Pipeline([\n",
        "            ('count', FunctionTransformer(get_capital_letters, validate=False)),\n",
        "        ]))\n",
        "    ])),\n",
        "    ('clf', MultinomialNB())])\n",
        "\n",
        "classifier5.fit(x_train, y_train.ravel())\n",
        "\n",
        "predicted5 = classifier5.predict(x_test)\n",
        "num_correct = 0\n",
        "for i in range(len(predicted5)):\n",
        "  if predicted5[i] == y_test[i]:\n",
        "    num_correct += 1\n",
        "\n",
        "print(num_correct)\n",
        "print(num_correct/len(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4405d486-bab6-437f-d921-d74c482c5fd3",
        "id": "V-RrYOcDSd7V"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12510\n",
            "0.8671842506585332\n"
          ]
        }
      ],
      "source": [
        "# normal bag of words model and proportion of capital letters\n",
        "classifier6 = Pipeline([\n",
        "    ('features', FeatureUnion([\n",
        "        ('text', Pipeline([\n",
        "            ('vectorizer', CountVectorizer(min_df=0,max_df=0.95)),\n",
        "            ('tfidf', TfidfTransformer()),\n",
        "        ])),\n",
        "        ('capital', Pipeline([\n",
        "            ('count', FunctionTransformer(get_capital_letters, validate=False)),\n",
        "        ])),\n",
        "        ('pos', Pipeline([\n",
        "            ('count', FunctionTransformer(get_pos_words, validate=False)),\n",
        "        ]))\n",
        "    ])),\n",
        "    ('clf', MultinomialNB())])\n",
        "\n",
        "classifier6.fit(x_train, y_train.ravel())\n",
        "\n",
        "predicted6 = classifier6.predict(x_test)\n",
        "num_correct = 0\n",
        "for i in range(len(predicted6)):\n",
        "  if predicted6[i] == y_test[i]:\n",
        "    num_correct += 1\n",
        "\n",
        "print(num_correct)\n",
        "print(num_correct/len(y_test))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}