{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as  np\n",
    "from gensim.models import Word2Vec\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 'title', 'class'], dtype='object')\n",
      "Index(['index', 'text', 'class'], dtype='object')\n",
      "   index                                              title  class\n",
      "0      0  [law, enforcement, high, alert, following, thr...      1\n",
      "2      2  [unbelievable, obama, attorney, general, says,...      1\n",
      "3      3  [bobby, jindal, raised, hindu, uses, story, ch...      0\n",
      "4      4  [satan, 2, russia, unvelis, image, terrifying,...      1\n",
      "5      5  [time, christian, group, sues, amazon, splc, d...      1\n",
      "   index                                               text  class\n",
      "0      0  [comment, expected, barack, obama, members, fy...      1\n",
      "1      1                    [post, votes, hillary, already]      1\n",
      "2      2  [demonstrators, gathered, last, night, exercis...      1\n",
      "3      3  [dozen, politically, active, pastors, came, pr...      0\n",
      "4      4  [rs, 28, sarmat, missile, dubbed, satan, 2, re...      1\n"
     ]
    }
   ],
   "source": [
    "df_title = pd.read_pickle('./data/clean_title.pkl')\n",
    "df_text = pd.read_pickle('./data/clean_text.pkl')\n",
    "print(df_title.columns)\n",
    "print(df_text.columns)\n",
    "print(df_title.head())\n",
    "print(df_text.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657028\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Key 'wuz' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m model_title\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data/model_title\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_title\u001b[38;5;241m.\u001b[39mcorpus_total_words)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mmodel_text\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwv\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwuz\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/ai-course/lib/python3.10/site-packages/gensim/models/keyedvectors.py:403\u001b[0m, in \u001b[0;36mKeyedVectors.__getitem__\u001b[0;34m(self, key_or_keys)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get vector representation of `key_or_keys`.\u001b[39;00m\n\u001b[1;32m    390\u001b[0m \n\u001b[1;32m    391\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    400\u001b[0m \n\u001b[1;32m    401\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key_or_keys, _KEY_TYPES):\n\u001b[0;32m--> 403\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey_or_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m vstack([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_vector(key) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m key_or_keys])\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/ai-course/lib/python3.10/site-packages/gensim/models/keyedvectors.py:446\u001b[0m, in \u001b[0;36mKeyedVectors.get_vector\u001b[0;34m(self, key, norm)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_vector\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    423\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the key's vector, as a 1D numpy array.\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \n\u001b[1;32m    425\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    444\u001b[0m \n\u001b[1;32m    445\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 446\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m norm:\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_norms()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/ai-course/lib/python3.10/site-packages/gensim/models/keyedvectors.py:420\u001b[0m, in \u001b[0;36mKeyedVectors.get_index\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not present\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Key 'wuz' not present\""
     ]
    }
   ],
   "source": [
    "model_text = Word2Vec(df_text[\"text\"], vector_size=100)\n",
    "model_title = Word2Vec(df_title[\"title\"], vector_size=100)\n",
    "model_text.save(\"./data/model_text\")\n",
    "model_title.save(\"./data/model_title\")\n",
    "print(model_title.corpus_total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_text = Word2Vec.load(\"./data/model_text\")\n",
    "model_title = Word2Vec.load(\"./data/model_title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70625, 3)\n",
      "(713, 3)\n",
      "Index(['index', 'text', 'class'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Split dataset\n",
    "def split(df, test_split=0.25):\n",
    "    df_test = df.sample(frac=test_split)\n",
    "    df_train = df.drop(df_test.index)\n",
    "    df_train.reset_index(drop=True)\n",
    "    return df_test, df_train\n",
    "\n",
    "\n",
    "df_text: pd.DataFrame = pd.read_pickle(\"./data/clean_text.pkl\")\n",
    "\n",
    "text_test, text_train = split(df_text,0.99)\n",
    "print(text_test.shape)\n",
    "print(text_train.shape)\n",
    "print(text_train.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method size of Tensor object at 0x2b05c32e0>\n"
     ]
    }
   ],
   "source": [
    "# make tensors\n",
    "def text_to_tensor(text_list, word_model):\n",
    "    vectors = [word_model.wv[word] for word in text_list if word in word_model.wv]\n",
    "    return torch.tensor(vectors)\n",
    "\n",
    "\n",
    "def stack_tensor(df: pd.DataFrame, col_name, word_model):\n",
    "    tensor_ls = []\n",
    "    for row in df.itertuples(index=False):\n",
    "        # print(row)\n",
    "        # print(row[df.columns.get_loc(col_name)])\n",
    "        tensor_ls.append(text_to_tensor(row[df.columns.get_loc(col_name)], word_model))\n",
    "    padded_ls = pad_sequence(tensor_ls,batch_first=True)\n",
    "    return torch.stack(tuple(padded_ls))\n",
    "\n",
    "\n",
    "text_train_tensor = stack_tensor(text_train, 'text', model_text)\n",
    "print(text_train_tensor.size())\n",
    "with open(\"./data/text_train_tensor\",\"wb\") as f:\n",
    "    pickle.dump(text_train_tensor,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([713, 2869, 100])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
