{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as  np\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader \n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "from torch import nn\n",
    "import pickle\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 'title', 'class'], dtype='object')\n",
      "Index(['index', 'text', 'class'], dtype='object')\n",
      "   index                                              title  class\n",
      "0      0  [law, enforcement, high, alert, following, thr...      1\n",
      "2      2  [unbelievable, obama, attorney, general, says,...      1\n",
      "3      3  [bobby, jindal, raised, hindu, uses, story, ch...      0\n",
      "4      4  [satan, 2, russia, unvelis, image, terrifying,...      1\n",
      "5      5  [time, christian, group, sues, amazon, splc, d...      1\n",
      "   index                                               text  class\n",
      "0      0  [comment, expected, barack, obama, members, fy...      1\n",
      "1      1                    [post, votes, hillary, already]      1\n",
      "2      2  [demonstrators, gathered, last, night, exercis...      1\n",
      "3      3  [dozen, politically, active, pastors, came, pr...      0\n",
      "4      4  [rs, 28, sarmat, missile, dubbed, satan, 2, re...      1\n"
     ]
    }
   ],
   "source": [
    "df_title = pd.read_pickle('./data/clean_title.pkl')\n",
    "df_text = pd.read_pickle('./data/clean_text.pkl')\n",
    "print(df_title.columns)\n",
    "print(df_text.columns)\n",
    "print(df_title.head())\n",
    "print(df_text.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: 23187031\n"
     ]
    }
   ],
   "source": [
    "model_text = Word2Vec( pd.concat([df_text[\"text\"] , df_title[\"title\"]],ignore_index=True) , vector_size=300)\n",
    "print(\"text: {0}\".format(model_text.corpus_total_words))\n",
    "model_text.wv.save_word2vec_format(\"./data/model_text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = gensim.downloader.load(\"word2vec-google-news-300\")\n",
    "pretrained_model.vectors_lockf = np.ones(len(pretrained_model), dtype=np.float32)\n",
    "merged_keyed_vectors = pretrained_model.intersect_word2vec_format(\n",
    "    \"./data/model_text\", binary=True, lockf=1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nf/g_pc_4zd2sx16tjwwb4r4fhm0000gn/T/ipykernel_72111/2303759884.py:10: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  return torch.tensor(vectors)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([713, 12203, 300])\n",
      "torch.Size([713])\n"
     ]
    }
   ],
   "source": [
    "# test with smaller amount of data\n",
    "FRACTION = 0.01\n",
    "size = int(df_text.shape[0] * FRACTION)\n",
    "print(size)\n",
    "\n",
    "\n",
    "# make tensors\n",
    "def text_to_tensor(text_list, merged_keyed_vectors):\n",
    "    vectors = [merged_keyed_vectors.wv[word] for word in text_list if word in merged_keyed_vectors.wv]\n",
    "    return torch.tensor(vectors)\n",
    "\n",
    "\n",
    "def stack_tensor(df: pd.DataFrame, col_name, word_model):\n",
    "    tensor_ls = []\n",
    "    label_ls = []\n",
    "    for row in df.itertuples(index=False):\n",
    "        # print(row[df.columns.get_loc('class')])\n",
    "        # print(row[df.columns.get_loc(col_name)])\n",
    "        label_ls.append(row[df.columns.get_loc(\"class\")])\n",
    "        tensor_ls.append(text_to_tensor(row[df.columns.get_loc(col_name)], word_model))\n",
    "    padded_ls = pad_sequence(tensor_ls, batch_first=True)\n",
    "    return torch.tensor(label_ls), torch.stack(tuple(padded_ls))\n",
    "\n",
    "\n",
    "text_labels_tensor, text_tensor = stack_tensor(\n",
    "    df_text.iloc[:size, :], \n",
    "    col_name=\"text\", \n",
    "    word_model=model_text\n",
    ")\n",
    "print(text_tensor.size())\n",
    "print(text_labels_tensor.size())\n",
    "text_dataset = TensorDataset(text_tensor, text_labels_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142\n",
      "571\n"
     ]
    }
   ],
   "source": [
    "def split(tensor_dataset, test_split=0.2):\n",
    "    test_size = int(len(tensor_dataset) * test_split)\n",
    "    train_size = int(len(tensor_dataset) - test_size)\n",
    "    print(test_size)\n",
    "    print(train_size)\n",
    "    train_data, test_data = random_split(tensor_dataset, [train_size, test_size])\n",
    "    return train_data, test_data\n",
    "\n",
    "train_text_tensor, test_text_tensor = split(text_dataset,0.2)\n",
    "\n",
    "with open(\"./data/train_text\",\"wb\") as f:\n",
    "    pickle.dump(train_text_tensor,f)\n",
    "with open(\"./data/test_text\",\"wb\") as f:\n",
    "    pickle.dump(train_text_tensor,f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
