{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn \n",
    "import pickle\n",
    "import torch\n",
    "gpu = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassificationModel(nn.Module):\n",
    "    def __init__(self, x_size, hidden_layer_size, dropout, activation_fn):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.first_layer = nn.Linear(x_size, hidden_layer_size)\n",
    "        self.hidden_layer = nn.Linear(hidden_layer_size, hidden_layer_size)\n",
    "        self.output_projection_1 = nn.Linear(hidden_layer_size, 1)\n",
    "        self.activation = activation_fn\n",
    "        self.normalisation = nn.BatchNorm1d(hidden_layer_size)\n",
    "        self.dropout = nn.Dropout1d(dropout)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.x_size = x_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first_layer(x)\n",
    "        for _ in range(3):\n",
    "            x = self.hidden_layer(x)\n",
    "            if x.size(0) > 1:\n",
    "                x = self.normalisation(x)\n",
    "            x = self.activation(x)\n",
    "            x = self.dropout(x)\n",
    "\n",
    "        out = self.output_projection_1(x)\n",
    "        out_distribution = self.sigmoid(out)\n",
    "        return out_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    train_dataloader, test_dataloader, loss_function, num_epochs, model, model_optimiser, batch_size\n",
    "):\n",
    "    # A counter for the number of gradient updates we've performed.\n",
    "    num_iter = 0\n",
    "\n",
    "    # Iterate `num_epochs` times.\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Starting epoch {}\".format(epoch + 1))\n",
    "        # Iterate over the train_dataloader, unpacking the images and labels\n",
    "        for data, labels in train_dataloader:\n",
    "            # If we're using the GPU, move reshaped_images and labels to the GPU.\n",
    "            if gpu:\n",
    "                data = data.to(gpu)\n",
    "                labels = labels.to(gpu)\n",
    "\n",
    "            # Run the forward pass through the model to get predicted log distribution.\n",
    "            predicted = model(data)\n",
    "\n",
    "            # reshape\n",
    "            labels = torch.unsqueeze(labels, 1)\n",
    "   \n",
    "            # Calculate the loss\n",
    "            batch_loss = loss_function(predicted, labels)\n",
    "\n",
    "            # Clear the gradients as we prepare to backprop.\n",
    "            model_optimiser.zero_grad()\n",
    "\n",
    "            # Backprop (backward pass), which calculates gradients.\n",
    "            batch_loss.backward()\n",
    "\n",
    "            # Take a gradient step to update parameters.\n",
    "            model_optimiser.step()\n",
    "\n",
    "            # Increment gradient update counter.\n",
    "            num_iter += 1\n",
    "\n",
    "            # Calculate test set loss and accuracy every 500 gradient updates\n",
    "            # It's standard to have this as a separate evaluate function, but\n",
    "            # we'll place it inline for didactic purposes.\n",
    "            if num_iter % 500 == 0:\n",
    "                # Set model to eval mode, which turns off dropout.\n",
    "                model.eval()\n",
    "                # Counters for the num of examples we get right / total num of examples.\n",
    "                num_correct = 0\n",
    "                total_examples = 0\n",
    "                total_test_loss = 0\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    # Iterate over the test dataloader\n",
    "                    for test_data, test_labels in test_dataloader:\n",
    "\n",
    "                        # If we're using the GPU, move tensors to the GPU.\n",
    "                        if gpu:\n",
    "                            test_data = test_data.to(gpu)\n",
    "                            test_labels = test_labels.to(gpu)\n",
    "                        \n",
    "                        # reshape\n",
    "                        test_labels = torch.unsqueeze(test_labels, 1)\n",
    "\n",
    "                        # Run the forward pass to get predicted distribution.\n",
    "                        predicted = model(test_data)\n",
    "                               \n",
    "                        # Calculate loss for this test batch. This is averaged, so multiply\n",
    "                        # by the number of examples in batch to get a total.\n",
    "                        total_test_loss += loss_function(predicted, test_labels)\n",
    "\n",
    "                        # Get predicted labels (argmax)\n",
    "                        predicted_labels = (predicted.data > 0.5).int()\n",
    "\n",
    "                        # Count the number of examples in this batch\n",
    "                        total_examples += test_labels.size(0)\n",
    "\n",
    "                        # Count the total number of correctly predicted labels.\n",
    "                        # predicted == labels generates a ByteTensor in indices where\n",
    "                        # predicted and labels match, so we can sum to get the num correct.\n",
    "                        num_correct += torch.sum(predicted_labels == test_labels.data)\n",
    "                        \n",
    "                accuracy = num_correct / total_examples\n",
    "                average_test_loss = total_test_loss / total_examples\n",
    "                print(\n",
    "                    \"Iteration {}. Test Loss {}. Test Accuracy {}. Total Examples {}\".format(\n",
    "                        num_iter, average_test_loss, accuracy, total_examples\n",
    "                    )\n",
    "                )\n",
    "                # Set the model back to train mode, which activates dropout again.\n",
    "                model.train()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72134, 13)\n",
      "(72122, 13)\n"
     ]
    }
   ],
   "source": [
    "# open data \n",
    "with open(\"./data/content_features_cv.pkl\",\"rb\") as f:\n",
    "    content_features_df = pickle.load(f)\n",
    "\n",
    "# drop values with 0 words per sentence\n",
    "print(content_features_df.shape)\n",
    "content_features_df = content_features_df[content_features_df[\"words_per_sentence_median\"] != 0]\n",
    "print(content_features_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verbs_third_person</th>\n",
       "      <th>verbs_others</th>\n",
       "      <th>words_per_sentence_median</th>\n",
       "      <th>num_of_sentences</th>\n",
       "      <th>adverbs_rate</th>\n",
       "      <th>nouns_rate</th>\n",
       "      <th>adjectives_rate</th>\n",
       "      <th>verbs_third_person_rate</th>\n",
       "      <th>verbs_others_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.717984</td>\n",
       "      <td>0.770385</td>\n",
       "      <td>-0.595685</td>\n",
       "      <td>0.748949</td>\n",
       "      <td>-0.720809</td>\n",
       "      <td>-0.800266</td>\n",
       "      <td>-0.476424</td>\n",
       "      <td>-0.249705</td>\n",
       "      <td>-0.093286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.926451</td>\n",
       "      <td>-0.790361</td>\n",
       "      <td>-1.945393</td>\n",
       "      <td>-0.784336</td>\n",
       "      <td>-0.025852</td>\n",
       "      <td>-2.170633</td>\n",
       "      <td>-2.451724</td>\n",
       "      <td>-2.500203</td>\n",
       "      <td>-0.460167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.868412</td>\n",
       "      <td>-0.663814</td>\n",
       "      <td>-0.516291</td>\n",
       "      <td>-0.731464</td>\n",
       "      <td>-0.894548</td>\n",
       "      <td>-0.219161</td>\n",
       "      <td>-0.081364</td>\n",
       "      <td>-1.308763</td>\n",
       "      <td>0.915637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.723991</td>\n",
       "      <td>0.643838</td>\n",
       "      <td>0.357050</td>\n",
       "      <td>0.801821</td>\n",
       "      <td>-0.193986</td>\n",
       "      <td>0.473297</td>\n",
       "      <td>0.396531</td>\n",
       "      <td>1.010062</td>\n",
       "      <td>-0.282644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.404101</td>\n",
       "      <td>-0.663814</td>\n",
       "      <td>1.309785</td>\n",
       "      <td>-0.493540</td>\n",
       "      <td>-0.426788</td>\n",
       "      <td>1.392055</td>\n",
       "      <td>1.741989</td>\n",
       "      <td>0.799170</td>\n",
       "      <td>-0.989323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   verbs_third_person  verbs_others  words_per_sentence_median  \\\n",
       "0            0.717984      0.770385                  -0.595685   \n",
       "1           -0.926451     -0.790361                  -1.945393   \n",
       "2           -0.868412     -0.663814                  -0.516291   \n",
       "3            1.723991      0.643838                   0.357050   \n",
       "4           -0.404101     -0.663814                   1.309785   \n",
       "\n",
       "   num_of_sentences  adverbs_rate  nouns_rate  adjectives_rate  \\\n",
       "0          0.748949     -0.720809   -0.800266        -0.476424   \n",
       "1         -0.784336     -0.025852   -2.170633        -2.451724   \n",
       "2         -0.731464     -0.894548   -0.219161        -0.081364   \n",
       "3          0.801821     -0.193986    0.473297         0.396531   \n",
       "4         -0.493540     -0.426788    1.392055         1.741989   \n",
       "\n",
       "   verbs_third_person_rate  verbs_others_rate  \n",
       "0                -0.249705          -0.093286  \n",
       "1                -2.500203          -0.460167  \n",
       "2                -1.308763           0.915637  \n",
       "3                 1.010062          -0.282644  \n",
       "4                 0.799170          -0.989323  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataloader\n",
    "labels = content_features_df[\"label\"].values\n",
    "features = content_features_df.drop(\"label\", axis=1)\n",
    "features = features.drop(\"dale_chall\", axis=1) # due to NaN\n",
    "features = features.drop(\"smog\", axis=1) # due to NaN\n",
    "features = features.drop(\"automatic_readability\", axis=1) # due to NaN\n",
    "\n",
    "\n",
    "\n",
    "# standardise data\n",
    "features = features.apply(lambda x: (x - x.mean()) / x.std())\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([72122, 9])\n",
      "torch.Size([72122])\n"
     ]
    }
   ],
   "source": [
    "features = features.values\n",
    "\n",
    "features_tensor = torch.tensor(features, dtype=torch.float32)\n",
    "labels_tensor = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(features_tensor,labels_tensor)\n",
    "print(features_tensor.shape)\n",
    "print(labels_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57697\n",
      "14425\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "num_epochs = 2\n",
    "hidden_layer_size = 512\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset,test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57697\n",
      "Starting epoch 1\n",
      "Iteration 500. Test Loss 6.25303316116333. Test Accuracy 0.48305025696754456. Total Examples 14425\n",
      "Iteration 1000. Test Loss 6.25303316116333. Test Accuracy 0.48305025696754456. Total Examples 14425\n",
      "Iteration 1500. Test Loss 6.25303316116333. Test Accuracy 0.48305025696754456. Total Examples 14425\n",
      "Iteration 2000. Test Loss 6.25303316116333. Test Accuracy 0.48305025696754456. Total Examples 14425\n",
      "Iteration 2500. Test Loss 6.25303316116333. Test Accuracy 0.48305025696754456. Total Examples 14425\n",
      "Iteration 3000. Test Loss 6.25303316116333. Test Accuracy 0.48305025696754456. Total Examples 14425\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m optimiser \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters())\n\u001b[1;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39mto(gpu)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimiser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 18\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_dataloader, test_dataloader, loss_function, num_epochs, model, model_optimiser, batch_size)\u001b[0m\n\u001b[1;32m     15\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(gpu)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Run the forward pass through the model to get predicted log distribution.\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m predicted \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# reshape\u001b[39;00m\n\u001b[1;32m     21\u001b[0m labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39munsqueeze(labels, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/ai-course/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/ai-course/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 16\u001b[0m, in \u001b[0;36mTextClassificationModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfirst_layer(x)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m---> 16\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     18\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalisation(x)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/ai-course/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/ai-course/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/ai-course/lib/python3.10/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model object\n",
    "sequence_length = len(train_dataset)\n",
    "print(sequence_length)\n",
    "model = TextClassificationModel(\n",
    "    x_size=10, hidden_layer_size=hidden_layer_size, dropout=0.5, activation_fn=nn.LeakyReLU()\n",
    ")\n",
    "loss = nn.BCELoss()\n",
    "optimiser = torch.optim.SGD(model.parameters())\n",
    "model.to(gpu)\n",
    "train(\n",
    "    train_dataloader, \n",
    "    test_dataloader, \n",
    "    loss, \n",
    "    num_epochs, \n",
    "    model, \n",
    "    optimiser,\n",
    "    batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57697\n",
      "Starting epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/limjohn/.pyenv/versions/3.10.12/envs/ai-course/lib/python3.10/site-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 500. Test Loss 0.04337087646126747. Test Accuracy 0.4800693094730377. Total Examples 14425\n",
      "Iteration 1000. Test Loss 0.043358366936445236. Test Accuracy 0.4800693094730377. Total Examples 14425\n",
      "Iteration 1500. Test Loss 0.04334966838359833. Test Accuracy 0.4800693094730377. Total Examples 14425\n",
      "Iteration 2000. Test Loss 0.04333999752998352. Test Accuracy 0.5199306607246399. Total Examples 14425\n",
      "Iteration 2500. Test Loss 0.043330688029527664. Test Accuracy 0.5199306607246399. Total Examples 14425\n",
      "Iteration 3000. Test Loss 0.0433267280459404. Test Accuracy 0.5199306607246399. Total Examples 14425\n",
      "Iteration 3500. Test Loss 0.043323077261447906. Test Accuracy 0.5199306607246399. Total Examples 14425\n",
      "Starting epoch 2\n",
      "Iteration 4000. Test Loss 0.043318286538124084. Test Accuracy 0.5199306607246399. Total Examples 14425\n",
      "Iteration 4500. Test Loss 0.0433167964220047. Test Accuracy 0.5199306607246399. Total Examples 14425\n",
      "Iteration 5000. Test Loss 0.04331349581480026. Test Accuracy 0.5199306607246399. Total Examples 14425\n",
      "Iteration 5500. Test Loss 0.043310634791851044. Test Accuracy 0.5199306607246399. Total Examples 14425\n",
      "Iteration 6000. Test Loss 0.0433083213865757. Test Accuracy 0.5199306607246399. Total Examples 14425\n",
      "Iteration 6500. Test Loss 0.04330766573548317. Test Accuracy 0.5199306607246399. Total Examples 14425\n",
      "Iteration 7000. Test Loss 0.043306298553943634. Test Accuracy 0.5199306607246399. Total Examples 14425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TextClassificationModel(\n",
       "  (first_layer): Linear(in_features=14, out_features=512, bias=True)\n",
       "  (hidden_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (output_projection_1): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (activation): Softmax(dim=None)\n",
       "  (normalisation): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout1d(p=0.5, inplace=False)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model object\n",
    "sequence_length = len(train_dataset)\n",
    "print(sequence_length)\n",
    "model = TextClassificationModel(\n",
    "    x_size=14, hidden_layer_size=hidden_layer_size, dropout=0.5, activation_fn=nn.Softmax()\n",
    ")\n",
    "loss = nn.BCELoss()\n",
    "optimiser = torch.optim.SGD(model.parameters())\n",
    "model.to(gpu)\n",
    "train(\n",
    "    train_dataloader, \n",
    "    test_dataloader, \n",
    "    loss, \n",
    "    num_epochs, \n",
    "    model, \n",
    "    optimiser,\n",
    "    batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57697\n",
      "Starting epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/limjohn/.pyenv/versions/3.10.12/envs/ai-course/lib/python3.10/site-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 500. Test Loss 0.66214519739151. Test Accuracy 0.4800693094730377. Total Examples 14425\n",
      "Iteration 1000. Test Loss 0.6613492369651794. Test Accuracy 0.4800693094730377. Total Examples 14425\n",
      "Iteration 1500. Test Loss 0.6639080047607422. Test Accuracy 0.4800693094730377. Total Examples 14425\n",
      "Iteration 2000. Test Loss 0.6675491333007812. Test Accuracy 0.4800693094730377. Total Examples 14425\n",
      "Iteration 2500. Test Loss 0.6670762896537781. Test Accuracy 0.4800693094730377. Total Examples 14425\n",
      "Iteration 3000. Test Loss 0.6615761518478394. Test Accuracy 0.4800693094730377. Total Examples 14425\n",
      "Iteration 3500. Test Loss 0.6659291982650757. Test Accuracy 0.4800693094730377. Total Examples 14425\n",
      "Starting epoch 2\n",
      "Iteration 4000. Test Loss 0.6626461148262024. Test Accuracy 0.4800693094730377. Total Examples 14425\n",
      "Iteration 4500. Test Loss 0.6651015281677246. Test Accuracy 0.4800693094730377. Total Examples 14425\n",
      "Iteration 5000. Test Loss 0.6644758582115173. Test Accuracy 0.4800693094730377. Total Examples 14425\n",
      "Iteration 5500. Test Loss 0.6662989258766174. Test Accuracy 0.4800693094730377. Total Examples 14425\n",
      "Iteration 6000. Test Loss 0.6619985103607178. Test Accuracy 0.4800693094730377. Total Examples 14425\n",
      "Iteration 6500. Test Loss 0.6659818291664124. Test Accuracy 0.4800693094730377. Total Examples 14425\n",
      "Iteration 7000. Test Loss 0.6623609662055969. Test Accuracy 0.4800693094730377. Total Examples 14425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TextClassificationModel(\n",
       "  (first_layer): Linear(in_features=14, out_features=512, bias=True)\n",
       "  (hidden_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (output_projection_1): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (activation): LogSoftmax(dim=None)\n",
       "  (normalisation): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout1d(p=0.5, inplace=False)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model object\n",
    "sequence_length = len(train_dataset)\n",
    "print(sequence_length)\n",
    "model = TextClassificationModel(\n",
    "    x_size=14, hidden_layer_size=hidden_layer_size, dropout=0.5, activation_fn=nn.LogSoftmax()\n",
    ")\n",
    "loss = nn.BCELoss()\n",
    "optimiser = torch.optim.SGD(model.parameters())\n",
    "model.to(gpu)\n",
    "train(\n",
    "    train_dataloader, \n",
    "    test_dataloader, \n",
    "    loss, \n",
    "    num_epochs, \n",
    "    model, \n",
    "    optimiser,\n",
    "    batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57697\n",
      "Starting epoch 1\n",
      "Iteration 500. Test Loss 0.04263605922460556. Test Accuracy 0.6635701656341553. Total Examples 14425\n",
      "Iteration 1000. Test Loss 0.04245109111070633. Test Accuracy 0.6237088441848755. Total Examples 14425\n",
      "Iteration 1500. Test Loss 0.042880818247795105. Test Accuracy 0.5796880125999451. Total Examples 14425\n",
      "Iteration 2000. Test Loss 0.04270308092236519. Test Accuracy 0.5458579063415527. Total Examples 14425\n",
      "Iteration 2500. Test Loss 0.042698945850133896. Test Accuracy 0.5435008406639099. Total Examples 14425\n",
      "Iteration 3000. Test Loss 0.042544566094875336. Test Accuracy 0.6569843888282776. Total Examples 14425\n",
      "Iteration 3500. Test Loss 0.042570021003484726. Test Accuracy 0.5872443914413452. Total Examples 14425\n",
      "Starting epoch 2\n",
      "Iteration 4000. Test Loss 0.04223562404513359. Test Accuracy 0.5421143770217896. Total Examples 14425\n",
      "Iteration 4500. Test Loss 0.04246094077825546. Test Accuracy 0.6119237542152405. Total Examples 14425\n",
      "Iteration 5000. Test Loss 0.04258371517062187. Test Accuracy 0.5332409143447876. Total Examples 14425\n",
      "Iteration 5500. Test Loss 0.04246226325631142. Test Accuracy 0.5265858173370361. Total Examples 14425\n",
      "Iteration 6000. Test Loss 0.042367130517959595. Test Accuracy 0.6549739837646484. Total Examples 14425\n",
      "Iteration 6500. Test Loss 0.04229627177119255. Test Accuracy 0.5319930911064148. Total Examples 14425\n",
      "Iteration 7000. Test Loss 0.04242405295372009. Test Accuracy 0.5875909924507141. Total Examples 14425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TextClassificationModel(\n",
       "  (first_layer): Linear(in_features=14, out_features=512, bias=True)\n",
       "  (hidden_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (output_projection_1): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (activation): LogSigmoid()\n",
       "  (normalisation): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout1d(p=0.5, inplace=False)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model object\n",
    "sequence_length = len(train_dataset)\n",
    "print(sequence_length)\n",
    "model = TextClassificationModel(\n",
    "    x_size=14, hidden_layer_size=hidden_layer_size, dropout=0.5, activation_fn=nn.LogSigmoid()\n",
    ")\n",
    "loss = nn.BCELoss()\n",
    "optimiser = torch.optim.SGD(model.parameters())\n",
    "model.to(gpu)\n",
    "train(\n",
    "    train_dataloader, \n",
    "    test_dataloader, \n",
    "    loss, \n",
    "    num_epochs, \n",
    "    model, \n",
    "    optimiser,\n",
    "    batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57697\n",
      "Starting epoch 1\n",
      "Iteration 500. Test Loss 0.043149884790182114. Test Accuracy 0.49143847823143005. Total Examples 14425\n",
      "Iteration 1000. Test Loss 0.04288288205862045. Test Accuracy 0.6681455969810486. Total Examples 14425\n",
      "Iteration 1500. Test Loss 0.0430869534611702. Test Accuracy 0.4882495701313019. Total Examples 14425\n",
      "Iteration 2000. Test Loss 0.04264602065086365. Test Accuracy 0.6201040148735046. Total Examples 14425\n",
      "Iteration 2500. Test Loss 0.04270919784903526. Test Accuracy 0.672443687915802. Total Examples 14425\n",
      "Iteration 3000. Test Loss 0.04276537522673607. Test Accuracy 0.6437435150146484. Total Examples 14425\n",
      "Iteration 3500. Test Loss 0.04256577789783478. Test Accuracy 0.6772270202636719. Total Examples 14425\n",
      "Starting epoch 2\n",
      "Iteration 4000. Test Loss 0.042286764830350876. Test Accuracy 0.6465857625007629. Total Examples 14425\n",
      "Iteration 4500. Test Loss 0.04228523001074791. Test Accuracy 0.6516464352607727. Total Examples 14425\n",
      "Iteration 5000. Test Loss 0.042310163378715515. Test Accuracy 0.6637781858444214. Total Examples 14425\n",
      "Iteration 5500. Test Loss 0.04221539571881294. Test Accuracy 0.6189254522323608. Total Examples 14425\n",
      "Iteration 6000. Test Loss 0.042318712919950485. Test Accuracy 0.6635701656341553. Total Examples 14425\n",
      "Iteration 6500. Test Loss 0.04219000041484833. Test Accuracy 0.6567071080207825. Total Examples 14425\n",
      "Iteration 7000. Test Loss 0.04233180359005928. Test Accuracy 0.6757712364196777. Total Examples 14425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TextClassificationModel(\n",
       "  (first_layer): Linear(in_features=14, out_features=512, bias=True)\n",
       "  (hidden_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (output_projection_1): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (activation): Sigmoid()\n",
       "  (normalisation): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout1d(p=0.5, inplace=False)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model object\n",
    "sequence_length = len(train_dataset)\n",
    "print(sequence_length)\n",
    "model = TextClassificationModel(\n",
    "    x_size=14, hidden_layer_size=hidden_layer_size, dropout=0.5, activation_fn=nn.Sigmoid()\n",
    ")\n",
    "loss = nn.BCELoss()\n",
    "optimiser = torch.optim.SGD(model.parameters())\n",
    "model.to(gpu)\n",
    "train(\n",
    "    train_dataloader, \n",
    "    test_dataloader, \n",
    "    loss, \n",
    "    num_epochs, \n",
    "    model, \n",
    "    optimiser,\n",
    "    batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57697\n",
      "Starting epoch 1\n",
      "Iteration 500. Test Loss 0.042029641568660736. Test Accuracy 0.6265511512756348. Total Examples 14425\n",
      "Iteration 1000. Test Loss 0.041758958250284195. Test Accuracy 0.6156672239303589. Total Examples 14425\n",
      "Iteration 1500. Test Loss 0.042377766221761703. Test Accuracy 0.5815597772598267. Total Examples 14425\n",
      "Iteration 2000. Test Loss 0.04187173396348953. Test Accuracy 0.6275910139083862. Total Examples 14425\n",
      "Iteration 2500. Test Loss 0.04198487102985382. Test Accuracy 0.6338301301002502. Total Examples 14425\n",
      "Iteration 3000. Test Loss 0.04144539311528206. Test Accuracy 0.6688387989997864. Total Examples 14425\n",
      "Iteration 3500. Test Loss 0.04200553521513939. Test Accuracy 0.640069305896759. Total Examples 14425\n",
      "Starting epoch 2\n",
      "Iteration 4000. Test Loss 0.04094213992357254. Test Accuracy 0.6861698627471924. Total Examples 14425\n",
      "Iteration 4500. Test Loss 0.04198361933231354. Test Accuracy 0.6788908243179321. Total Examples 14425\n",
      "Iteration 5000. Test Loss 0.042284201830625534. Test Accuracy 0.6253032684326172. Total Examples 14425\n",
      "Iteration 5500. Test Loss 0.041612181812524796. Test Accuracy 0.6610051989555359. Total Examples 14425\n",
      "Iteration 6000. Test Loss 0.041699010878801346. Test Accuracy 0.6517157554626465. Total Examples 14425\n",
      "Iteration 6500. Test Loss 0.04198472946882248. Test Accuracy 0.673622190952301. Total Examples 14425\n",
      "Iteration 7000. Test Loss 0.04181757569313049. Test Accuracy 0.6621143817901611. Total Examples 14425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TextClassificationModel(\n",
       "  (first_layer): Linear(in_features=14, out_features=512, bias=True)\n",
       "  (hidden_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (output_projection_1): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (activation): ELU(alpha=1.0)\n",
       "  (normalisation): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout1d(p=0.5, inplace=False)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model object\n",
    "sequence_length = len(train_dataset)\n",
    "print(sequence_length)\n",
    "model = TextClassificationModel(\n",
    "    x_size=14, hidden_layer_size=hidden_layer_size, dropout=0.5, activation_fn=nn.ELU()\n",
    ")\n",
    "loss = nn.BCELoss()\n",
    "optimiser = torch.optim.SGD(model.parameters())\n",
    "model.to(gpu)\n",
    "train(\n",
    "    train_dataloader, \n",
    "    test_dataloader, \n",
    "    loss, \n",
    "    num_epochs, \n",
    "    model, \n",
    "    optimiser,\n",
    "    batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57697\n",
      "Starting epoch 1\n",
      "Iteration 500. Test Loss 0.04225274920463562. Test Accuracy 0.6016637682914734. Total Examples 14425\n",
      "Iteration 1000. Test Loss 0.04167064651846886. Test Accuracy 0.628284215927124. Total Examples 14425\n",
      "Iteration 1500. Test Loss 0.04177100211381912. Test Accuracy 0.6625303030014038. Total Examples 14425\n",
      "Iteration 2000. Test Loss 0.042112383991479874. Test Accuracy 0.6406932473182678. Total Examples 14425\n",
      "Iteration 2500. Test Loss 0.04186621680855751. Test Accuracy 0.6616291403770447. Total Examples 14425\n",
      "Iteration 3000. Test Loss 0.04206791892647743. Test Accuracy 0.6363951563835144. Total Examples 14425\n",
      "Iteration 3500. Test Loss 0.04131036624312401. Test Accuracy 0.6587175130844116. Total Examples 14425\n",
      "Starting epoch 2\n",
      "Iteration 4000. Test Loss 0.04169654846191406. Test Accuracy 0.6546273827552795. Total Examples 14425\n",
      "Iteration 4500. Test Loss 0.041790299117565155. Test Accuracy 0.6634315252304077. Total Examples 14425\n",
      "Iteration 5000. Test Loss 0.041840799152851105. Test Accuracy 0.6505372524261475. Total Examples 14425\n",
      "Iteration 5500. Test Loss 0.042186189442873. Test Accuracy 0.6562911868095398. Total Examples 14425\n",
      "Iteration 6000. Test Loss 0.04137120395898819. Test Accuracy 0.6882495880126953. Total Examples 14425\n",
      "Iteration 6500. Test Loss 0.04185102880001068. Test Accuracy 0.6682149171829224. Total Examples 14425\n",
      "Iteration 7000. Test Loss 0.041892051696777344. Test Accuracy 0.6837434768676758. Total Examples 14425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TextClassificationModel(\n",
       "  (first_layer): Linear(in_features=14, out_features=512, bias=True)\n",
       "  (hidden_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (output_projection_1): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (activation): CELU(alpha=1.0)\n",
       "  (normalisation): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout1d(p=0.5, inplace=False)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model object\n",
    "sequence_length = len(train_dataset)\n",
    "print(sequence_length)\n",
    "model = TextClassificationModel(\n",
    "    x_size=14, hidden_layer_size=hidden_layer_size, dropout=0.5, activation_fn=nn.CELU()\n",
    ")\n",
    "loss = nn.BCELoss()\n",
    "optimiser = torch.optim.SGD(model.parameters())\n",
    "model.to(gpu)\n",
    "train(\n",
    "    train_dataloader, \n",
    "    test_dataloader, \n",
    "    loss, \n",
    "    num_epochs, \n",
    "    model, \n",
    "    optimiser,\n",
    "    batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57697\n",
      "Starting epoch 1\n",
      "Iteration 500. Test Loss 0.042681608349084854. Test Accuracy 0.6067937612533569. Total Examples 14425\n",
      "Iteration 1000. Test Loss 0.04262861981987953. Test Accuracy 0.6078336238861084. Total Examples 14425\n",
      "Iteration 1500. Test Loss 0.04254849627614021. Test Accuracy 0.6361871957778931. Total Examples 14425\n",
      "Iteration 2000. Test Loss 0.04248280078172684. Test Accuracy 0.6075563430786133. Total Examples 14425\n",
      "Iteration 2500. Test Loss 0.04258333519101143. Test Accuracy 0.5919584035873413. Total Examples 14425\n",
      "Iteration 3000. Test Loss 0.042230408638715744. Test Accuracy 0.659480094909668. Total Examples 14425\n",
      "Iteration 3500. Test Loss 0.04211507365107536. Test Accuracy 0.6472790241241455. Total Examples 14425\n",
      "Starting epoch 2\n",
      "Iteration 4000. Test Loss 0.042209818959236145. Test Accuracy 0.6542807817459106. Total Examples 14425\n",
      "Iteration 4500. Test Loss 0.04189028590917587. Test Accuracy 0.6583015322685242. Total Examples 14425\n",
      "Iteration 5000. Test Loss 0.041849736124277115. Test Accuracy 0.6671057343482971. Total Examples 14425\n",
      "Iteration 5500. Test Loss 0.042026814073324203. Test Accuracy 0.6582322120666504. Total Examples 14425\n",
      "Iteration 6000. Test Loss 0.04195362329483032. Test Accuracy 0.66246098279953. Total Examples 14425\n",
      "Iteration 6500. Test Loss 0.0420568622648716. Test Accuracy 0.6591334342956543. Total Examples 14425\n",
      "Iteration 7000. Test Loss 0.0419224388897419. Test Accuracy 0.663916826248169. Total Examples 14425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TextClassificationModel(\n",
       "  (first_layer): Linear(in_features=14, out_features=512, bias=True)\n",
       "  (hidden_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (output_projection_1): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (activation): ReLU()\n",
       "  (normalisation): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout1d(p=0.5, inplace=False)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model object\n",
    "sequence_length = len(train_dataset)\n",
    "print(sequence_length)\n",
    "model = TextClassificationModel(\n",
    "    x_size=14, hidden_layer_size=hidden_layer_size, dropout=0.5, activation_fn=nn.ReLU()\n",
    ")\n",
    "loss = nn.BCELoss()\n",
    "optimiser = torch.optim.SGD(model.parameters())\n",
    "model.to(gpu)\n",
    "train(\n",
    "    train_dataloader, \n",
    "    test_dataloader, \n",
    "    loss, \n",
    "    num_epochs, \n",
    "    model, \n",
    "    optimiser,\n",
    "    batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chosen CELU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57697\n",
      "Starting epoch 1\n",
      "Iteration 500. Test Loss 0.04229911044239998. Test Accuracy 0.6399306654930115. Total Examples 14425\n",
      "Iteration 1000. Test Loss 0.04267789423465729. Test Accuracy 0.5491161346435547. Total Examples 14425\n",
      "Iteration 1500. Test Loss 0.04150907322764397. Test Accuracy 0.6176083087921143. Total Examples 14425\n",
      "Iteration 2000. Test Loss 0.04198576882481575. Test Accuracy 0.6494280695915222. Total Examples 14425\n",
      "Iteration 2500. Test Loss 0.042047031223773956. Test Accuracy 0.6320277452468872. Total Examples 14425\n",
      "Iteration 3000. Test Loss 0.04149436205625534. Test Accuracy 0.629462718963623. Total Examples 14425\n",
      "Iteration 3500. Test Loss 0.04182291775941849. Test Accuracy 0.6607279181480408. Total Examples 14425\n",
      "Starting epoch 2\n",
      "Iteration 4000. Test Loss 0.04104803502559662. Test Accuracy 0.635008692741394. Total Examples 14425\n",
      "Iteration 4500. Test Loss 0.040842898190021515. Test Accuracy 0.6558752059936523. Total Examples 14425\n",
      "Iteration 5000. Test Loss 0.04230674356222153. Test Accuracy 0.6112998127937317. Total Examples 14425\n",
      "Iteration 5500. Test Loss 0.040185458958148956. Test Accuracy 0.6658579111099243. Total Examples 14425\n",
      "Iteration 6000. Test Loss 0.0417974591255188. Test Accuracy 0.6509532332420349. Total Examples 14425\n",
      "Iteration 6500. Test Loss 0.042088720947504044. Test Accuracy 0.6393761038780212. Total Examples 14425\n",
      "Iteration 7000. Test Loss 0.041854698210954666. Test Accuracy 0.6198266744613647. Total Examples 14425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TextClassificationModel(\n",
       "  (first_layer): Linear(in_features=14, out_features=512, bias=True)\n",
       "  (hidden_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (output_projection_1): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (activation): CELU(alpha=1.0)\n",
       "  (normalisation): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout1d(p=0.5, inplace=False)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model object\n",
    "sequence_length = len(train_dataset)\n",
    "print(sequence_length)\n",
    "model = TextClassificationModel(\n",
    "    x_size=14, hidden_layer_size=hidden_layer_size, dropout=0.5, activation_fn=nn.CELU()\n",
    ")\n",
    "loss = nn.BCELoss()\n",
    "optimiser = torch.optim.AdamW(model.parameters())\n",
    "model.to(gpu)\n",
    "train(\n",
    "    train_dataloader, \n",
    "    test_dataloader, \n",
    "    loss, \n",
    "    num_epochs, \n",
    "    model, \n",
    "    optimiser,\n",
    "    batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57697\n",
      "Starting epoch 1\n",
      "Iteration 500. Test Loss 0.041883617639541626. Test Accuracy 0.6204506158828735. Total Examples 14425\n",
      "Iteration 1000. Test Loss 0.042376305907964706. Test Accuracy 0.6529635787010193. Total Examples 14425\n",
      "Iteration 1500. Test Loss 0.04201788082718849. Test Accuracy 0.6098440289497375. Total Examples 14425\n",
      "Iteration 2000. Test Loss 0.04104060307145119. Test Accuracy 0.642149031162262. Total Examples 14425\n",
      "Iteration 2500. Test Loss 0.04225935786962509. Test Accuracy 0.5839167833328247. Total Examples 14425\n",
      "Iteration 3000. Test Loss 0.041369594633579254. Test Accuracy 0.6577469706535339. Total Examples 14425\n",
      "Iteration 3500. Test Loss 0.041180793195962906. Test Accuracy 0.6343847513198853. Total Examples 14425\n",
      "Starting epoch 2\n",
      "Iteration 4000. Test Loss 0.04167741537094116. Test Accuracy 0.6154592633247375. Total Examples 14425\n",
      "Iteration 4500. Test Loss 0.042834002524614334. Test Accuracy 0.5527209639549255. Total Examples 14425\n",
      "Iteration 5000. Test Loss 0.04139428958296776. Test Accuracy 0.6118544340133667. Total Examples 14425\n",
      "Iteration 5500. Test Loss 0.041763562709093094. Test Accuracy 0.6409012079238892. Total Examples 14425\n",
      "Iteration 6000. Test Loss 0.04299798607826233. Test Accuracy 0.5276256203651428. Total Examples 14425\n",
      "Iteration 6500. Test Loss 0.04197265952825546. Test Accuracy 0.6210744976997375. Total Examples 14425\n",
      "Iteration 7000. Test Loss 0.04241159185767174. Test Accuracy 0.6610745191574097. Total Examples 14425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TextClassificationModel(\n",
       "  (first_layer): Linear(in_features=14, out_features=512, bias=True)\n",
       "  (hidden_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (output_projection_1): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (activation): CELU(alpha=1.0)\n",
       "  (normalisation): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout1d(p=0.5, inplace=False)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model object\n",
    "sequence_length = len(train_dataset)\n",
    "print(sequence_length)\n",
    "model = TextClassificationModel(\n",
    "    x_size=14, hidden_layer_size=hidden_layer_size, dropout=0.5, activation_fn=nn.CELU()\n",
    ")\n",
    "loss = nn.BCELoss()\n",
    "optimiser = torch.optim.Adam(model.parameters())\n",
    "model.to(gpu)\n",
    "train(\n",
    "    train_dataloader, \n",
    "    test_dataloader, \n",
    "    loss, \n",
    "    num_epochs, \n",
    "    model, \n",
    "    optimiser,\n",
    "    batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57697\n",
      "Starting epoch 1\n",
      "Iteration 500. Test Loss 0.042512018233537674. Test Accuracy 0.5700519680976868. Total Examples 14425\n",
      "Iteration 1000. Test Loss 0.0417768694460392. Test Accuracy 0.6092200875282288. Total Examples 14425\n",
      "Iteration 1500. Test Loss 0.04246056452393532. Test Accuracy 0.579064130783081. Total Examples 14425\n",
      "Iteration 2000. Test Loss 0.04187612235546112. Test Accuracy 0.6644020676612854. Total Examples 14425\n",
      "Iteration 2500. Test Loss 0.04182278737425804. Test Accuracy 0.6208665370941162. Total Examples 14425\n",
      "Iteration 3000. Test Loss 0.041488975286483765. Test Accuracy 0.6180242896080017. Total Examples 14425\n",
      "Iteration 3500. Test Loss 0.04224379360675812. Test Accuracy 0.588492214679718. Total Examples 14425\n",
      "Starting epoch 2\n",
      "Iteration 4000. Test Loss 0.04364825040102005. Test Accuracy 0.502183735370636. Total Examples 14425\n",
      "Iteration 4500. Test Loss 0.04146573320031166. Test Accuracy 0.6429809331893921. Total Examples 14425\n",
      "Iteration 5000. Test Loss 0.04218197986483574. Test Accuracy 0.6020797491073608. Total Examples 14425\n",
      "Iteration 5500. Test Loss 0.04180473834276199. Test Accuracy 0.601802408695221. Total Examples 14425\n",
      "Iteration 6000. Test Loss 0.04354822263121605. Test Accuracy 0.5113344788551331. Total Examples 14425\n",
      "Iteration 6500. Test Loss 0.04225711524486542. Test Accuracy 0.5937608480453491. Total Examples 14425\n",
      "Iteration 7000. Test Loss 0.0419129841029644. Test Accuracy 0.6273829936981201. Total Examples 14425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TextClassificationModel(\n",
       "  (first_layer): Linear(in_features=14, out_features=512, bias=True)\n",
       "  (hidden_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (output_projection_1): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (activation): CELU(alpha=1.0)\n",
       "  (normalisation): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout1d(p=0.5, inplace=False)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model object\n",
    "sequence_length = len(train_dataset)\n",
    "print(sequence_length)\n",
    "model = TextClassificationModel(\n",
    "    x_size=14, hidden_layer_size=hidden_layer_size, dropout=0.5, activation_fn=nn.CELU()\n",
    ")\n",
    "loss = nn.BCELoss()\n",
    "optimiser = torch.optim.ASGD(model.parameters())\n",
    "model.to(gpu)\n",
    "train(\n",
    "    train_dataloader, \n",
    "    test_dataloader, \n",
    "    loss, \n",
    "    num_epochs, \n",
    "    model, \n",
    "    optimiser,\n",
    "    batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57697\n",
      "Starting epoch 1\n",
      "Iteration 500. Test Loss 0.044213201850652695. Test Accuracy 0.543708860874176. Total Examples 14425\n",
      "Iteration 1000. Test Loss 0.04310188069939613. Test Accuracy 0.5199306607246399. Total Examples 14425\n",
      "Iteration 1500. Test Loss 0.043413400650024414. Test Accuracy 0.4800693094730377. Total Examples 14425\n",
      "Iteration 2000. Test Loss 0.04327463358640671. Test Accuracy 0.5200693011283875. Total Examples 14425\n",
      "Iteration 2500. Test Loss 0.04385981336236. Test Accuracy 0.4800693094730377. Total Examples 14425\n",
      "Iteration 3000. Test Loss 0.04352565109729767. Test Accuracy 0.4800693094730377. Total Examples 14425\n",
      "Iteration 3500. Test Loss 0.04338870942592621. Test Accuracy 0.4806932508945465. Total Examples 14425\n",
      "Starting epoch 2\n",
      "Iteration 4000. Test Loss 0.04329801723361015. Test Accuracy 0.5199306607246399. Total Examples 14425\n",
      "Iteration 4500. Test Loss 0.04334932938218117. Test Accuracy 0.4806932508945465. Total Examples 14425\n",
      "Iteration 5000. Test Loss 0.04348139837384224. Test Accuracy 0.48062393069267273. Total Examples 14425\n",
      "Iteration 5500. Test Loss 0.043265022337436676. Test Accuracy 0.5199306607246399. Total Examples 14425\n",
      "Iteration 6000. Test Loss 0.043263498693704605. Test Accuracy 0.5199306607246399. Total Examples 14425\n",
      "Iteration 6500. Test Loss 0.04378217086195946. Test Accuracy 0.5199306607246399. Total Examples 14425\n",
      "Iteration 7000. Test Loss 0.043286364525556564. Test Accuracy 0.5199306607246399. Total Examples 14425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TextClassificationModel(\n",
       "  (first_layer): Linear(in_features=14, out_features=512, bias=True)\n",
       "  (hidden_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (output_projection_1): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (activation): CELU(alpha=1.0)\n",
       "  (normalisation): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout1d(p=0.5, inplace=False)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model object\n",
    "sequence_length = len(train_dataset)\n",
    "print(sequence_length)\n",
    "model = TextClassificationModel(\n",
    "    x_size=14, hidden_layer_size=hidden_layer_size, dropout=0.5, activation_fn=nn.CELU()\n",
    ")\n",
    "loss = nn.BCELoss()\n",
    "optimiser = torch.optim.RMSprop(model.parameters())\n",
    "model.to(gpu)\n",
    "train(\n",
    "    train_dataloader, \n",
    "    test_dataloader, \n",
    "    loss, \n",
    "    num_epochs, \n",
    "    model, \n",
    "    optimiser,\n",
    "    batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57697\n",
      "Starting epoch 1\n",
      "Iteration 500. Test Loss 0.0425371378660202. Test Accuracy 0.5600693225860596. Total Examples 14425\n",
      "Iteration 1000. Test Loss 0.04241449758410454. Test Accuracy 0.5780242681503296. Total Examples 14425\n",
      "Iteration 1500. Test Loss 0.04301730915904045. Test Accuracy 0.5188907980918884. Total Examples 14425\n",
      "Iteration 2000. Test Loss 0.042496711015701294. Test Accuracy 0.600901186466217. Total Examples 14425\n",
      "Iteration 2500. Test Loss 0.042248472571372986. Test Accuracy 0.6099133491516113. Total Examples 14425\n",
      "Iteration 3000. Test Loss 0.04158344864845276. Test Accuracy 0.6232235431671143. Total Examples 14425\n",
      "Iteration 3500. Test Loss 0.04222334176301956. Test Accuracy 0.6149740219116211. Total Examples 14425\n",
      "Starting epoch 2\n",
      "Iteration 4000. Test Loss 0.04236486926674843. Test Accuracy 0.5654072761535645. Total Examples 14425\n",
      "Iteration 4500. Test Loss 0.04253574088215828. Test Accuracy 0.5920970439910889. Total Examples 14425\n",
      "Iteration 5000. Test Loss 0.04203486442565918. Test Accuracy 0.6546273827552795. Total Examples 14425\n",
      "Iteration 5500. Test Loss 0.042371850460767746. Test Accuracy 0.5584055185317993. Total Examples 14425\n",
      "Iteration 6000. Test Loss 0.03997653350234032. Test Accuracy 0.6794453859329224. Total Examples 14425\n",
      "Iteration 6500. Test Loss 0.04099058732390404. Test Accuracy 0.6847140192985535. Total Examples 14425\n",
      "Iteration 7000. Test Loss 0.04344070702791214. Test Accuracy 0.4849913418292999. Total Examples 14425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TextClassificationModel(\n",
       "  (first_layer): Linear(in_features=14, out_features=512, bias=True)\n",
       "  (hidden_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (output_projection_1): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (activation): CELU(alpha=1.0)\n",
       "  (normalisation): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout1d(p=0.5, inplace=False)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model object\n",
    "sequence_length = len(train_dataset)\n",
    "print(sequence_length)\n",
    "model = TextClassificationModel(\n",
    "    x_size=14, hidden_layer_size=hidden_layer_size, dropout=0.5, activation_fn=nn.CELU()\n",
    ")\n",
    "loss = nn.BCELoss()\n",
    "optimiser = torch.optim.NAdam(model.parameters())\n",
    "model.to(gpu)\n",
    "train(\n",
    "    train_dataloader, \n",
    "    test_dataloader, \n",
    "    loss, \n",
    "    num_epochs, \n",
    "    model, \n",
    "    optimiser,\n",
    "    batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57697\n",
      "Starting epoch 1\n",
      "Iteration 500. Test Loss 0.041691068559885025. Test Accuracy 0.6289081573486328. Total Examples 14425\n",
      "Iteration 1000. Test Loss 0.04177755489945412. Test Accuracy 0.6216984391212463. Total Examples 14425\n",
      "Iteration 1500. Test Loss 0.0423731654882431. Test Accuracy 0.6393761038780212. Total Examples 14425\n",
      "Iteration 2000. Test Loss 0.04237179458141327. Test Accuracy 0.6293240785598755. Total Examples 14425\n",
      "Iteration 2500. Test Loss 0.04245670139789581. Test Accuracy 0.674246072769165. Total Examples 14425\n",
      "Iteration 3000. Test Loss 0.0421287976205349. Test Accuracy 0.6017330884933472. Total Examples 14425\n",
      "Iteration 3500. Test Loss 0.0412408821284771. Test Accuracy 0.6526169776916504. Total Examples 14425\n",
      "Starting epoch 2\n",
      "Iteration 4000. Test Loss 0.04159567505121231. Test Accuracy 0.6244021058082581. Total Examples 14425\n",
      "Iteration 4500. Test Loss 0.04142557457089424. Test Accuracy 0.6269670724868774. Total Examples 14425\n",
      "Iteration 5000. Test Loss 0.04144078120589256. Test Accuracy 0.6671057343482971. Total Examples 14425\n",
      "Iteration 5500. Test Loss 0.04003872349858284. Test Accuracy 0.6723743677139282. Total Examples 14425\n",
      "Iteration 6000. Test Loss 0.04354120418429375. Test Accuracy 0.5077296495437622. Total Examples 14425\n",
      "Iteration 6500. Test Loss 0.04201994836330414. Test Accuracy 0.6485961675643921. Total Examples 14425\n",
      "Iteration 7000. Test Loss 0.04111086204648018. Test Accuracy 0.666273832321167. Total Examples 14425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TextClassificationModel(\n",
       "  (first_layer): Linear(in_features=14, out_features=512, bias=True)\n",
       "  (hidden_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (output_projection_1): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (activation): CELU(alpha=1.0)\n",
       "  (normalisation): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout1d(p=0.5, inplace=False)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model object\n",
    "sequence_length = len(train_dataset)\n",
    "print(sequence_length)\n",
    "model = TextClassificationModel(\n",
    "    x_size=14, hidden_layer_size=hidden_layer_size, dropout=0.5, activation_fn=nn.CELU()\n",
    ")\n",
    "loss = nn.BCELoss()\n",
    "optimiser = torch.optim.RAdam(model.parameters())\n",
    "model.to(gpu)\n",
    "train(\n",
    "    train_dataloader, \n",
    "    test_dataloader, \n",
    "    loss, \n",
    "    num_epochs, \n",
    "    model, \n",
    "    optimiser,\n",
    "    batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57697\n",
      "Starting epoch 1\n",
      "Iteration 500. Test Loss 0.041302766650915146. Test Accuracy 0.6063085198402405. Total Examples 14425\n",
      "Iteration 1000. Test Loss 0.04150797799229622. Test Accuracy 0.6045753955841064. Total Examples 14425\n",
      "Iteration 1500. Test Loss 0.041378773748874664. Test Accuracy 0.6053379774093628. Total Examples 14425\n",
      "Iteration 2000. Test Loss 0.041336141526699066. Test Accuracy 0.6080415844917297. Total Examples 14425\n",
      "Iteration 2500. Test Loss 0.041558410972356796. Test Accuracy 0.5966030955314636. Total Examples 14425\n",
      "Iteration 3000. Test Loss 0.04142079874873161. Test Accuracy 0.6022183895111084. Total Examples 14425\n",
      "Iteration 3500. Test Loss 0.04137151315808296. Test Accuracy 0.6083881855010986. Total Examples 14425\n",
      "Starting epoch 2\n",
      "Iteration 4000. Test Loss 0.04153791069984436. Test Accuracy 0.6031889319419861. Total Examples 14425\n",
      "Iteration 4500. Test Loss 0.04156554117798805. Test Accuracy 0.5918197631835938. Total Examples 14425\n",
      "Iteration 5000. Test Loss 0.04142121970653534. Test Accuracy 0.6040207743644714. Total Examples 14425\n",
      "Iteration 5500. Test Loss 0.041409265249967575. Test Accuracy 0.601455807685852. Total Examples 14425\n",
      "Iteration 6000. Test Loss 0.041503336280584335. Test Accuracy 0.6043674349784851. Total Examples 14425\n",
      "Iteration 6500. Test Loss 0.041401367634534836. Test Accuracy 0.5959792137145996. Total Examples 14425\n",
      "Iteration 7000. Test Loss 0.041477806866168976. Test Accuracy 0.5909878611564636. Total Examples 14425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TextClassificationModel(\n",
       "  (first_layer): Linear(in_features=14, out_features=512, bias=True)\n",
       "  (hidden_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (output_projection_1): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (activation): CELU(alpha=1.0)\n",
       "  (normalisation): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout1d(p=0.5, inplace=False)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model object\n",
    "sequence_length = len(train_dataset)\n",
    "print(sequence_length)\n",
    "model = TextClassificationModel(\n",
    "    x_size=14, hidden_layer_size=hidden_layer_size, dropout=0.5, activation_fn=nn.CELU()\n",
    ")\n",
    "loss = nn.BCELoss()\n",
    "optimiser = torch.optim.Rprop(model.parameters())\n",
    "model.to(gpu)\n",
    "train(\n",
    "    train_dataloader, \n",
    "    test_dataloader, \n",
    "    loss, \n",
    "    num_epochs, \n",
    "    model, \n",
    "    optimiser,\n",
    "    batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chosen NAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57697\n",
      "Starting epoch 1\n",
      "Iteration 500. Test Loss 0.039066631346940994. Test Accuracy 0.6555979251861572. Total Examples 14425\n",
      "Iteration 1000. Test Loss 0.03696073219180107. Test Accuracy 0.6877642869949341. Total Examples 14425\n",
      "Iteration 1500. Test Loss 0.039150018244981766. Test Accuracy 0.6495667099952698. Total Examples 14425\n",
      "Iteration 2000. Test Loss 0.03693527728319168. Test Accuracy 0.6881109476089478. Total Examples 14425\n",
      "Iteration 2500. Test Loss 0.03580513224005699. Test Accuracy 0.709324061870575. Total Examples 14425\n",
      "Iteration 3000. Test Loss 0.0422854870557785. Test Accuracy 0.5538301467895508. Total Examples 14425\n",
      "Iteration 3500. Test Loss 0.03693638741970062. Test Accuracy 0.7001733183860779. Total Examples 14425\n",
      "Starting epoch 2\n",
      "Iteration 4000. Test Loss 0.036880213767290115. Test Accuracy 0.6958752274513245. Total Examples 14425\n",
      "Iteration 4500. Test Loss 0.03826221451163292. Test Accuracy 0.6969150900840759. Total Examples 14425\n",
      "Iteration 5000. Test Loss 0.03592642396688461. Test Accuracy 0.71549391746521. Total Examples 14425\n",
      "Iteration 5500. Test Loss 0.03844138979911804. Test Accuracy 0.7034315466880798. Total Examples 14425\n",
      "Iteration 6000. Test Loss 0.0368768572807312. Test Accuracy 0.6926863193511963. Total Examples 14425\n",
      "Iteration 6500. Test Loss 0.035379525274038315. Test Accuracy 0.7163951396942139. Total Examples 14425\n",
      "Iteration 7000. Test Loss 0.03564675524830818. Test Accuracy 0.7125823497772217. Total Examples 14425\n",
      "Starting epoch 3\n",
      "Iteration 7500. Test Loss 0.03492023050785065. Test Accuracy 0.7168804407119751. Total Examples 14425\n",
      "Iteration 8000. Test Loss 0.0357491597533226. Test Accuracy 0.710433304309845. Total Examples 14425\n",
      "Iteration 8500. Test Loss 0.03480612486600876. Test Accuracy 0.7205545902252197. Total Examples 14425\n",
      "Iteration 9000. Test Loss 0.03523203730583191. Test Accuracy 0.7198613286018372. Total Examples 14425\n",
      "Iteration 9500. Test Loss 0.034898173063993454. Test Accuracy 0.7163951396942139. Total Examples 14425\n",
      "Iteration 10000. Test Loss 0.035761136561632156. Test Accuracy 0.7159792184829712. Total Examples 14425\n",
      "Iteration 10500. Test Loss 0.04316006228327751. Test Accuracy 0.5199999809265137. Total Examples 14425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TextClassificationModel(\n",
       "  (first_layer): Linear(in_features=14, out_features=512, bias=True)\n",
       "  (hidden_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (output_projection_1): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (activation): CELU(alpha=1.0)\n",
       "  (normalisation): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout1d(p=0.01, inplace=False)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model object\n",
    "num_epochs = 3\n",
    "hidden_layer_size = 512\n",
    "sequence_length = len(train_dataset)\n",
    "print(sequence_length)\n",
    "model = TextClassificationModel(\n",
    "    x_size=14, hidden_layer_size=hidden_layer_size, dropout=0.01, activation_fn=nn.CELU()\n",
    ")\n",
    "loss = nn.BCELoss()\n",
    "optimiser = torch.optim.NAdam(model.parameters())\n",
    "model.to(gpu)\n",
    "train(\n",
    "    train_dataloader, \n",
    "    test_dataloader, \n",
    "    loss, \n",
    "    num_epochs, \n",
    "    model, \n",
    "    optimiser,\n",
    "    batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57697\n",
      "Starting epoch 1\n",
      "Iteration 500. Test Loss 0.03921680524945259. Test Accuracy 0.6517157554626465. Total Examples 14425\n",
      "Iteration 1000. Test Loss 0.03670905530452728. Test Accuracy 0.6888041496276855. Total Examples 14425\n",
      "Iteration 1500. Test Loss 0.038267191499471664. Test Accuracy 0.6729289293289185. Total Examples 14425\n",
      "Iteration 2000. Test Loss 0.036887798458337784. Test Accuracy 0.6888041496276855. Total Examples 14425\n",
      "Iteration 2500. Test Loss 0.03635110706090927. Test Accuracy 0.6963604688644409. Total Examples 14425\n",
      "Iteration 3000. Test Loss 0.04040705785155296. Test Accuracy 0.6627383232116699. Total Examples 14425\n",
      "Iteration 3500. Test Loss 0.0373803973197937. Test Accuracy 0.6897746920585632. Total Examples 14425\n",
      "Starting epoch 2\n",
      "Iteration 4000. Test Loss 0.036191798746585846. Test Accuracy 0.699826717376709. Total Examples 14425\n",
      "Iteration 4500. Test Loss 0.0371435210108757. Test Accuracy 0.6937955021858215. Total Examples 14425\n",
      "Iteration 5000. Test Loss 0.035946622490882874. Test Accuracy 0.7202079892158508. Total Examples 14425\n",
      "Iteration 5500. Test Loss 0.03665761277079582. Test Accuracy 0.7007278800010681. Total Examples 14425\n",
      "Iteration 6000. Test Loss 0.035888414829969406. Test Accuracy 0.7031542658805847. Total Examples 14425\n",
      "Iteration 6500. Test Loss 0.03508797660470009. Test Accuracy 0.7129982709884644. Total Examples 14425\n",
      "Iteration 7000. Test Loss 0.03514978662133217. Test Accuracy 0.7134835124015808. Total Examples 14425\n",
      "Starting epoch 3\n",
      "Iteration 7500. Test Loss 0.03493540361523628. Test Accuracy 0.711611807346344. Total Examples 14425\n",
      "Iteration 8000. Test Loss 0.03540404886007309. Test Accuracy 0.7099480032920837. Total Examples 14425\n",
      "Iteration 8500. Test Loss 0.03523031249642372. Test Accuracy 0.7144540548324585. Total Examples 14425\n",
      "Iteration 9000. Test Loss 0.035466961562633514. Test Accuracy 0.711611807346344. Total Examples 14425\n",
      "Iteration 9500. Test Loss 0.034960124641656876. Test Accuracy 0.717227041721344. Total Examples 14425\n",
      "Iteration 10000. Test Loss 0.03485290706157684. Test Accuracy 0.7175736427307129. Total Examples 14425\n",
      "Iteration 10500. Test Loss 0.042316410690546036. Test Accuracy 0.6788215041160583. Total Examples 14425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TextClassificationModel(\n",
       "  (first_layer): Linear(in_features=14, out_features=512, bias=True)\n",
       "  (hidden_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (output_projection_1): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (activation): CELU(alpha=1.0)\n",
       "  (normalisation): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout1d(p=0.01, inplace=False)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model object\n",
    "num_epochs = 3\n",
    "hidden_layer_size = 512\n",
    "sequence_length = len(train_dataset)\n",
    "print(sequence_length)\n",
    "model = TextClassificationModel(\n",
    "    x_size=14, hidden_layer_size=hidden_layer_size, dropout=0.01, activation_fn=nn.CELU()\n",
    ")\n",
    "loss = nn.BCELoss()\n",
    "optimiser = torch.optim.NAdam(model.parameters(),lr=0.001)\n",
    "model.to(gpu)\n",
    "train(\n",
    "    train_dataloader, \n",
    "    test_dataloader, \n",
    "    loss, \n",
    "    num_epochs, \n",
    "    model, \n",
    "    optimiser,\n",
    "    batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57697\n",
      "Starting epoch 1\n",
      "Iteration 500. Test Loss 0.03992997109889984. Test Accuracy 0.6357712149620056. Total Examples 14425\n",
      "Iteration 1000. Test Loss 0.03666790947318077. Test Accuracy 0.695459246635437. Total Examples 14425\n",
      "Iteration 1500. Test Loss 0.04080686718225479. Test Accuracy 0.6228769421577454. Total Examples 14425\n",
      "Iteration 2000. Test Loss 0.036699578166007996. Test Accuracy 0.696013867855072. Total Examples 14425\n",
      "Iteration 2500. Test Loss 0.03714744374155998. Test Accuracy 0.7081455588340759. Total Examples 14425\n",
      "Iteration 3000. Test Loss 0.044240668416023254. Test Accuracy 0.48062393069267273. Total Examples 14425\n",
      "Iteration 3500. Test Loss 0.037058163434267044. Test Accuracy 0.6994800567626953. Total Examples 14425\n",
      "Starting epoch 2\n",
      "Iteration 4000. Test Loss 0.0402972474694252. Test Accuracy 0.646793782711029. Total Examples 14425\n",
      "Iteration 4500. Test Loss 0.03661003336310387. Test Accuracy 0.7072443962097168. Total Examples 14425\n",
      "Iteration 5000. Test Loss 0.03809324651956558. Test Accuracy 0.706620454788208. Total Examples 14425\n",
      "Iteration 5500. Test Loss 0.04239208251237869. Test Accuracy 0.5360831618309021. Total Examples 14425\n",
      "Iteration 6000. Test Loss 0.042295221239328384. Test Accuracy 0.5430155992507935. Total Examples 14425\n",
      "Iteration 6500. Test Loss 0.03872046247124672. Test Accuracy 0.7154245972633362. Total Examples 14425\n",
      "Iteration 7000. Test Loss 0.040098145604133606. Test Accuracy 0.6819410920143127. Total Examples 14425\n",
      "Starting epoch 3\n",
      "Iteration 7500. Test Loss 0.039992526173591614. Test Accuracy 0.6999653577804565. Total Examples 14425\n",
      "Iteration 8000. Test Loss 0.04203791171312332. Test Accuracy 0.5679029226303101. Total Examples 14425\n",
      "Iteration 8500. Test Loss 0.0409286804497242. Test Accuracy 0.6763951182365417. Total Examples 14425\n",
      "Iteration 9000. Test Loss 0.04130757972598076. Test Accuracy 0.5969497561454773. Total Examples 14425\n",
      "Iteration 9500. Test Loss 0.040825020521879196. Test Accuracy 0.7163951396942139. Total Examples 14425\n",
      "Iteration 10000. Test Loss 0.04203197732567787. Test Accuracy 0.6974003314971924. Total Examples 14425\n",
      "Iteration 10500. Test Loss 0.04348336160182953. Test Accuracy 0.4800693094730377. Total Examples 14425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TextClassificationModel(\n",
       "  (first_layer): Linear(in_features=14, out_features=512, bias=True)\n",
       "  (hidden_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (output_projection_1): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (activation): CELU(alpha=1.0)\n",
       "  (normalisation): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout1d(p=0.01, inplace=False)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model object\n",
    "num_epochs = 3\n",
    "hidden_layer_size = 512\n",
    "sequence_length = len(train_dataset)\n",
    "print(sequence_length)\n",
    "model = TextClassificationModel(\n",
    "    x_size=14, hidden_layer_size=hidden_layer_size, dropout=0.01, activation_fn=nn.CELU()\n",
    ")\n",
    "loss = nn.BCELoss()\n",
    "optimiser = torch.optim.NAdam(model.parameters(),lr=0.004)\n",
    "model.to(gpu)\n",
    "train(\n",
    "    train_dataloader, \n",
    "    test_dataloader, \n",
    "    loss, \n",
    "    num_epochs, \n",
    "    model, \n",
    "    optimiser,\n",
    "    batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57697\n",
      "Starting epoch 1\n",
      "Iteration 500. Test Loss 0.037230927497148514. Test Accuracy 0.6919930577278137. Total Examples 14425\n",
      "Iteration 1000. Test Loss 0.03672466799616814. Test Accuracy 0.698717474937439. Total Examples 14425\n",
      "Iteration 1500. Test Loss 0.03663802146911621. Test Accuracy 0.699272096157074. Total Examples 14425\n",
      "Iteration 2000. Test Loss 0.03658523038029671. Test Accuracy 0.695459246635437. Total Examples 14425\n",
      "Iteration 2500. Test Loss 0.03648880496621132. Test Accuracy 0.700450599193573. Total Examples 14425\n",
      "Iteration 3000. Test Loss 0.03601334989070892. Test Accuracy 0.7055112719535828. Total Examples 14425\n",
      "Iteration 3500. Test Loss 0.03605044260621071. Test Accuracy 0.7029462456703186. Total Examples 14425\n",
      "Starting epoch 2\n",
      "Iteration 4000. Test Loss 0.039933402091264725. Test Accuracy 0.6205199360847473. Total Examples 14425\n",
      "Iteration 4500. Test Loss 0.03685532137751579. Test Accuracy 0.7014904618263245. Total Examples 14425\n",
      "Iteration 5000. Test Loss 0.03677619993686676. Test Accuracy 0.6918544173240662. Total Examples 14425\n",
      "Iteration 5500. Test Loss 0.03749654442071915. Test Accuracy 0.679792046546936. Total Examples 14425\n",
      "Iteration 6000. Test Loss 0.03695502132177353. Test Accuracy 0.6881109476089478. Total Examples 14425\n",
      "Iteration 6500. Test Loss 0.036918602883815765. Test Accuracy 0.7064818143844604. Total Examples 14425\n",
      "Iteration 7000. Test Loss 0.036098286509513855. Test Accuracy 0.7063431739807129. Total Examples 14425\n",
      "Starting epoch 3\n",
      "Iteration 7500. Test Loss 0.03745489567518234. Test Accuracy 0.6779202818870544. Total Examples 14425\n",
      "Iteration 8000. Test Loss 0.03620016574859619. Test Accuracy 0.7001733183860779. Total Examples 14425\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m optimiser \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mNAdam(model\u001b[38;5;241m.\u001b[39mparameters(),lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39mto(gpu)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimiser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 15\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_dataloader, test_dataloader, loss_function, num_epochs, model, model_optimiser, batch_size)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gpu:\n\u001b[1;32m     14\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(gpu)\n\u001b[0;32m---> 15\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgpu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Run the forward pass through the model to get predicted log distribution.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m predicted \u001b[38;5;241m=\u001b[39m model(data)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model object\n",
    "num_epochs = 3\n",
    "hidden_layer_size = 512\n",
    "sequence_length = len(train_dataset)\n",
    "print(sequence_length)\n",
    "model = TextClassificationModel(\n",
    "    x_size=9, hidden_layer_size=hidden_layer_size, dropout=0.001, activation_fn=nn.CELU()\n",
    ")\n",
    "loss = nn.BCELoss()\n",
    "optimiser = torch.optim.NAdam(model.parameters(),lr=0.001)\n",
    "model.to(gpu)\n",
    "train(\n",
    "    train_dataloader, \n",
    "    test_dataloader, \n",
    "    loss, \n",
    "    num_epochs, \n",
    "    model, \n",
    "    optimiser,\n",
    "    batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
